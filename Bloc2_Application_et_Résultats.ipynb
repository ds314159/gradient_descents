{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8f0c7f2-012f-49b3-bc96-2796761ae3d8",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "# **Régression Logistique sur un Dataset Réel** \n",
    "\n",
    "</div>\n",
    "<br><br>\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7846c555-d92d-4d6b-afb6-39adc619d9f5",
   "metadata": {},
   "source": [
    "## **Introduction**\n",
    "\n",
    "Dans ce volet, il s'agira de confronter les versions \"maison\" de nos algorithmes de descente de gradient et de prédiction à un jeu de données du réel. Ce jeu de données est un dataset issu d'une banque portugaise, dont l'objectif est d'identifier les clients les plus enclins à souscrire un produit financier. En plus d'être plus volumineux qu'un dataset académique, un jeu de données issu du terrain peut challenger la descente de gradient de par sa plus grande variabilité et son bruit, surtout en présence d'un déséquilibre entre les classes.\n",
    "\n",
    "Une première partie consistera à reproduire les mêmes traitements et choix que la démonstration, afin d'aboutir à un dataset ajusté et exploitatble par nos algorithmes.\n",
    "\n",
    "Dans la deuxième partie, la régression logistique sera appliquée avec les méthodes d'optimisation implémentées dans le Bloc-1, auxquelles ont été rajoutées deux implémentations de descente de gradient pénalisées, La ridge et la Lasso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1f12eb-3504-43f3-8712-28b0c8678d72",
   "metadata": {},
   "source": [
    "## **I- Reproduction des traitements et choix de variables dans le dataset**\n",
    "\n",
    "Cette partie se contente d'acquérir le dataset et de lui appliquer les mêmes traitements que dans la démonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "362bb1c7-3ba5-4927-b9af-1d6bd0899e1e",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "import statsmodels.api as sm\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "from Optimisations import * # fichier Optimisations.py: Nos descentes de gradients élaborés en bloc-1 + DG pénalisée Ridge + DG pénalisée Lasso\n",
    "from Outils import * # fichier Outils.py: les fonctions de prédiction, des outils de plot.."
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2ecc7462-2aea-4b72-9300-cdf86b0d57fc",
   "metadata": {},
   "source": [
    "#### **DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e2bb3cc-7259-4297-9d94-c23afa1e6e2a",
   "metadata": {},
   "source": [
    "data = pd.read_csv('bank.csv', header=0)\n",
    "data = data.dropna()\n",
    "print(data.shape)\n",
    "print(list(data.columns))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ac1566c-4374-41eb-84c4-cb1339faa826",
   "metadata": {},
   "source": [
    "data.dtypes"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "326c8e2b-bd50-4f29-9c8c-29f208b292a6",
   "metadata": {},
   "source": [
    "data.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "daa29fd8-deaf-4eec-9f3a-a57461b75325",
   "metadata": {},
   "source": [
    "#### **Grouping Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac9f97b3-e0bc-44a4-8cda-e1c483b6c0ef",
   "metadata": {},
   "source": [
    "data['education'].unique()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9357fe95-3e02-4f9b-820e-616318fa78f8",
   "metadata": {},
   "source": [
    "data['education']=np.where(data['education'] =='basic.9y', 'Basic', data['education'])\n",
    "data['education']=np.where(data['education'] =='basic.6y', 'Basic', data['education'])\n",
    "data['education']=np.where(data['education'] =='basic.4y', 'Basic', data['education'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3464de9c-374d-4a0f-81bf-b784ef41c0e8",
   "metadata": {},
   "source": [
    "data['education'].unique()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a8035d89-2b18-46a4-806e-7737a0c19866",
   "metadata": {},
   "source": [
    "#### **Exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4d31938-df78-47e9-ba8c-27c22607df60",
   "metadata": {},
   "source": [
    "data['y'].value_counts()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a5fe55f-1b35-4320-855c-67dd88efa0f3",
   "metadata": {},
   "source": [
    "sns.countplot(x='y', data=data, palette='hls', hue='y')\n",
    "plt.show()\n",
    "plt.savefig('count plot')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b39cd666-c8dd-4dce-b91a-7c380adabbc8",
   "metadata": {},
   "source": [
    "count_no_sub = len(data[data['y']==0])\n",
    "count_sub = len(data[data['y']==1])\n",
    "pct_of_no_sub = count_no_sub/(count_no_sub+count_sub)\n",
    "print(\"percentage of no subscription is\", pct_of_no_sub*100)\n",
    "pct_of_sub = count_sub/(count_no_sub+count_sub)\n",
    "print(\"percentage of subscription\", pct_of_sub*100)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "281a948f-e686-4b29-985c-0c2471e9b458",
   "metadata": {},
   "source": [
    "data.groupby('y').mean(numeric_only=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0acb2445-1a71-4d0e-b3b3-8985feceb9d5",
   "metadata": {},
   "source": [
    "data.groupby('job').mean(numeric_only=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c41a566a-2068-468c-8894-7284d70d0048",
   "metadata": {},
   "source": [
    "data.groupby('marital').mean(numeric_only=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ddb0996-9b70-41a9-a57b-127ff9354e48",
   "metadata": {},
   "source": [
    "data.groupby('education').mean(numeric_only=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c79c618a-e95d-4d75-9454-47bb838f88be",
   "metadata": {},
   "source": [
    "%matplotlib inline\n",
    "pd.crosstab(data.job,data.y).plot(kind='bar')\n",
    "plt.title('Purchase Frequency for Job Title')\n",
    "plt.xlabel('Job')\n",
    "plt.ylabel('Frequency of Purchase')\n",
    "plt.savefig('purchase_fre_job')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9736f90b-9e73-4fc2-a69d-c959a3404eea",
   "metadata": {},
   "source": [
    "table=pd.crosstab(data.marital,data.y)\n",
    "table.div(table.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True)\n",
    "plt.title('Stacked Bar Chart of Marital Status vs Purchase')\n",
    "plt.xlabel('Marital Status')\n",
    "plt.ylabel('Proportion of Customers')\n",
    "plt.savefig('mariral_vs_pur_stack')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0cfc0c1-4fe8-44a6-b761-2659a99a2e6d",
   "metadata": {},
   "source": [
    "table=pd.crosstab(data.education,data.y)\n",
    "table.div(table.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True)\n",
    "plt.title('Stacked Bar Chart of Education vs Purchase')\n",
    "plt.xlabel('Education')\n",
    "plt.ylabel('Proportion of Customers')\n",
    "plt.savefig('edu_vs_pur_stack')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e45b8b65-6846-4f6b-8e13-efad8d0c78b1",
   "metadata": {},
   "source": [
    "pd.crosstab(data.day_of_week,data.y).plot(kind='bar')\n",
    "plt.title('Purchase Frequency for Day of Week')\n",
    "plt.xlabel('Day of Week')\n",
    "plt.ylabel('Frequency of Purchase')\n",
    "plt.savefig('pur_dayofweek_bar')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bc26ee1-e238-4bf5-abf9-1f6676f37fe9",
   "metadata": {},
   "source": [
    "pd.crosstab(data.month,data.y).plot(kind='bar')\n",
    "plt.title('Purchase Frequency for Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Frequency of Purchase')\n",
    "plt.savefig('pur_fre_month_bar')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81bbcc1a-9534-413c-87fd-30029651b87e",
   "metadata": {},
   "source": [
    "data.age.hist()\n",
    "plt.title('Histogram of Age')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('hist_age')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6385e29-1857-4d34-8aec-ef60b62ee861",
   "metadata": {},
   "source": [
    "pd.crosstab(data.poutcome,data.y).plot(kind='bar')\n",
    "plt.title('Purchase Frequency for Poutcome')\n",
    "plt.xlabel('Poutcome')\n",
    "plt.ylabel('Frequency of Purchase')\n",
    "plt.savefig('pur_fre_pout_bar')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c968dfd6-f000-458b-aefa-d136eec30249",
   "metadata": {},
   "source": [
    "#### **Transformation Dummy variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "179af6b9-fc50-43bd-b5e7-7c6dfa03e905",
   "metadata": {},
   "source": [
    "cat_vars=['job','marital','education','default','housing','loan','contact','month','day_of_week','poutcome']\n",
    "for var in cat_vars:\n",
    "    cat_list='var'+'_'+var\n",
    "    cat_list = pd.get_dummies(data[var], prefix=var)\n",
    "    cat_list = cat_list.astype(int)\n",
    "    data1=data.join(cat_list)\n",
    "    data=data1\n",
    "cat_vars=['job','marital','education','default','housing','loan','contact','month','day_of_week','poutcome']\n",
    "data_vars=data.columns.values.tolist()\n",
    "to_keep=[i for i in data_vars if i not in cat_vars]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae5ccfc2-4cc5-4318-a304-d1d628c1d19c",
   "metadata": {},
   "source": [
    "# Trouver toutes les colonnes de type booléen et les convertir en int\n",
    "data[data.select_dtypes(['bool']).columns] = data.select_dtypes(['bool']).astype(int)\n",
    "\n",
    "data.dtypes[:50]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9eb8bce-961d-48bb-8529-7e2549eefa18",
   "metadata": {},
   "source": [
    "data_final=data[to_keep]\n",
    "data_final.columns.values"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "fe510610-c24a-4717-95b5-acf2b79a9f8d",
   "metadata": {},
   "source": [
    "#### **Oversampling using SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cdf45dff-7627-4f29-9236-cfa903f12262",
   "metadata": {},
   "source": [
    "X = data_final.loc[:, data_final.columns != 'y']\n",
    "y = data_final.loc[:, data_final.columns == 'y']\n",
    "from imblearn.over_sampling import SMOTE\n",
    "os = SMOTE(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "columns = X_train.columns\n",
    "os_data_X,os_data_y=os.fit_resample(X_train, y_train)\n",
    "os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\n",
    "os_data_y= pd.DataFrame(data=os_data_y,columns=['y'])\n",
    "# we can Check the numbers of our data\n",
    "print(\"length of oversampled data is \",len(os_data_X))\n",
    "print(\"Number of no subscription in oversampled data\",len(os_data_y[os_data_y['y']==0]))\n",
    "print(\"Number of subscription\",len(os_data_y[os_data_y['y']==1]))\n",
    "print(\"Proportion of no subscription data in oversampled data is \",len(os_data_y[os_data_y['y']==0])/len(os_data_X))\n",
    "print(\"Proportion of subscription data in oversampled data is \",len(os_data_y[os_data_y['y']==1])/len(os_data_X))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e06a31fe-8daf-474c-9512-acd77b230677",
   "metadata": {},
   "source": [
    "#### **Elimination des features les moins pertinentes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5dc4d548-4a7e-4033-973a-de94f1c44f70",
   "metadata": {},
   "source": [
    "cols=['euribor3m', 'job_blue-collar', 'job_housemaid', 'marital_unknown', 'education_illiterate', \n",
    "      'month_apr', 'month_aug', 'month_dec', 'month_jul', 'month_jun', 'month_mar', \n",
    "      'month_may', 'month_nov', 'month_oct', \"poutcome_failure\", \"poutcome_success\"] \n",
    "X=os_data_X[cols]\n",
    "y=os_data_y['y']\n",
    "logit_model=sm.Logit(y,X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a21ecd29-1c8b-4ce9-98bd-dbc1b9dea9f2",
   "metadata": {},
   "source": [
    "#### **Modèle de l'exemple**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9defef51-d129-4c1d-9663-ddff5a0413b9",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    C=1.0, \n",
    "    class_weight=None, \n",
    "    dual=False, \n",
    "    fit_intercept=True, \n",
    "    intercept_scaling=1, \n",
    "    max_iter=100, \n",
    "    multi_class='ovr', \n",
    "    n_jobs=1, \n",
    "    penalty='l2', \n",
    "    random_state=None, \n",
    "    solver='liblinear', \n",
    "    tol=0.0001, \n",
    "    verbose=0, \n",
    "    warm_start=False\n",
    ")\n",
    "\n",
    "logreg.fit(X_train, y_train)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0bbbff3a-3553-4e87-85b2-74dfdfdb0428",
   "metadata": {},
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a35016d1-5d9b-4ac0-9eab-fc7558afdb32",
   "metadata": {},
   "source": [
    "## **II- Régressions et résultats**\n",
    "\n",
    "Appliquons nos algorithmes de descente à ce dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "77ec804f-c157-4e10-8c68-5b167e971486",
   "metadata": {},
   "source": [
    "# paramètres \n",
    "n_features = X_train.shape[1]\n",
    "w_random = random_initialize_parameters(n_features)\n",
    "learning_rate = 0.5\n",
    "num_iterations = 1000\n",
    "batch_size = 256\n",
    "momentum = 0.9\n",
    "epsilon = 1e-8\n",
    "lambda_reg = 0.1  # Pour Ridge et Lasso\n",
    "\n",
    "\n",
    "# N'oublions pas que nos algorithmes fonctionnent avec des matrics et que nous avons des dataframes:\n",
    "X_train = X_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "\n",
    "X_test = X_test.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2bcc48ba-5e39-4d73-a4db-2a29928297e2",
   "metadata": {},
   "source": [
    "# descente de gradient simple:\n",
    "w_gd, costs_gd = gradient_descent(X_train, y_train, w_random, learning_rate, num_iterations)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9fcd9c8e-f15c-46bb-a61a-72557820245d",
   "metadata": {},
   "source": [
    "# descente de gradient stochastique :\n",
    "w_sgd, costs_sgd = stochastic_gradient_descent(X_train, y_train, w_random, learning_rate, num_epochs=8, batch_size=256)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b428e8c-0858-4589-9d1a-af9997978016",
   "metadata": {},
   "source": [
    "# descente de gradient avec momentum\n",
    "w_momentum, costs_momentum = gradient_descent_momentum(X_train, y_train, w_random, learning_rate, num_iterations=1000)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3d61be1b-ed20-4a59-91f4-4b86588cce95",
   "metadata": {},
   "source": [
    "# descente de gradient Nesterov\n",
    "w_nesterov, costs_nesterov = gradient_descent_nesterov(X_train, y_train, w_random, learning_rate, num_iterations)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dc59b494-f4d6-45bc-a7b3-400c89865212",
   "metadata": {},
   "source": [
    "# descente de gradient adagrad\n",
    "w_adagrad, costs_adagrad = gradient_descent_adagrad(X_train, y_train, w_random, learning_rate, num_iterations)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e4f8fe8-9ee6-497c-b696-d8f20c2e56f7",
   "metadata": {},
   "source": [
    "# descente de gradient RMSprop\n",
    "w_rmsprop, costs_rmsprop = gradient_descent_rmsprop(X_train, y_train, w_random, learning_rate, num_iterations)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9f13fce0-261d-4b5e-9f7d-cd8112a78ba1",
   "metadata": {},
   "source": [
    "# descente de gradient Adam\n",
    "w_adam, costs_adam = gradient_descent_adam(X_train, y_train, w_random, learning_rate, num_iterations)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2ef5b9a1-e467-4ff8-9dea-de49f3a07dea",
   "metadata": {},
   "source": [
    "# descente de gradient avec régularisation ridge\n",
    "w_ridge, costs_ridge = gradient_descent_ridge(X_train, y_train, w_random, learning_rate, num_iterations, lambda_reg)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "90349c1d-83f0-403c-93b3-a258adbf9e99",
   "metadata": {},
   "source": [
    "# descente de gradient avec régularisation Lasso\n",
    "w_lasso, costs_lasso = gradient_descent_lasso(X_train, y_train, w_random, learning_rate, num_iterations, lambda_reg)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0ef3a44d-3557-47cb-b878-37a5f072c4b0",
   "metadata": {},
   "source": [
    "# regroupons en dictionnaire nos résultats\n",
    "results_costs = {\n",
    "    'Gradient Descent': costs_gd,\n",
    "    'SGD': costs_sgd,\n",
    "    'Momentum': costs_momentum,\n",
    "    'Nesterov': costs_nesterov,\n",
    "    'AdaGrad': costs_adagrad,\n",
    "    'RMSProp': costs_rmsprop,\n",
    "    'Adam': costs_adam,\n",
    "    'Ridge': costs_ridge,\n",
    "    'Lasso': costs_lasso\n",
    "}\n",
    "\n",
    "results_weights = {\n",
    "    'Gradient Descent': w_gd,\n",
    "    'SGD': w_sgd,\n",
    "    'Momentum': w_momentum,\n",
    "    'Nesterov': w_nesterov,\n",
    "    'AdaGrad': w_adagrad,\n",
    "    'RMSProp': w_rmsprop,\n",
    "    'Adam': w_adam,\n",
    "    'Ridge': w_ridge,\n",
    "    'Lasso': w_lasso\n",
    "}\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "fb623227-5d99-446f-8db2-9ef1096e4bd2",
   "metadata": {},
   "source": [
    "#### **1- Courbes de convergence de la perte:**\n",
    "\n",
    "Comme le montre le graphe suivant, nos différentes méthodes de descente de gradient, ont toutes convergé avec une performance de rapidité notoire pour la descente de gradient Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "71757a61-c7f8-4965-8c38-34dccda98977",
   "metadata": {},
   "source": [
    "exclure = [\"RMSProp\"]\n",
    "plot_losses(results_costs, index_min=0, index_max=500, dontplot=exclure)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b803f5ea-b9ef-4ab8-9d55-c98fa329837d",
   "metadata": {},
   "source": [
    "Nous pouvons néanmoins constater que La descente de gradient RMSPop a pâti d'une instabilité, ne l'ayant pas empêché de converger, mais l'ayant contraint à osciller entre des valeurs de 0.45 et 0.5. Soit une amplitude de 0.05 en unité de perte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7c2a601a-2349-4e27-86e8-7f1f212d4d40",
   "metadata": {},
   "source": [
    "inclure = [\"RMSProp\"]\n",
    "plot_losses(results_costs, index_min=0, index_max=500, plot=inclure)\n",
    "plot_losses(results_costs, index_min=900, index_max=1000, plot=inclure)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a96728ed-aec0-4ed0-9ecc-86c78cdb60d2",
   "metadata": {},
   "source": [
    "#### **2- Prédictions avec les poids optimaux obtenus par chaque méthode:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d9f788-6728-4042-a722-dc81f2e6747d",
   "metadata": {},
   "source": [
    "Essayons d'utiliser nos poids maintenant, afin de prédire les labels sur le set de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0c08c2bf-7812-4e9d-88be-32d4ebd12335",
   "metadata": {},
   "source": [
    "# Dictionnaire pour stocker les prédictions des labels pour chaque algorithme\n",
    "results_labels = {}\n",
    "\n",
    "# Seuil de 0.5\n",
    "threshold = 0.5\n",
    "\n",
    "# Appliquer la prédiction pour chaque algorithme dans results_weights\n",
    "for algo, weights in results_weights.items():\n",
    "    # Calculer les probabilités avec sigmoid\n",
    "    probabilities = predict(X_test, weights)\n",
    "    \n",
    "    # Appliquer le seuil de 0.5 pour obtenir les prédictions en 0 ou 1\n",
    "    labels = (probabilities >= threshold).astype(int)\n",
    "    \n",
    "    # Stocker les labels dans le dictionnaire results_labels\n",
    "    results_labels[algo] = labels\n",
    "\n",
    "# Affichage des résultats de l'accuracy (nombre de bonnes réponses sur tout le dataset de test)\n",
    "for algo, labels in results_labels.items():\n",
    "    accuracy = np.mean(y_test == labels)\n",
    "    print(f\"Accuracy de l'algorithme {algo}: {accuracy:.4f}\")  "
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "08dfd825-5faa-42f7-836c-21cef9a94676",
   "metadata": {},
   "source": [
    "Nous avons globalement de très bons résultats en accuracy avec tous nos algorithmes. La différence sur un même résultat d'accuracy a résidé dans la vitesse de convergence, qui a eu lieu à partir de la 30ième itération pour Adam, et a coûté significativement plus d'itérations pour les autres algorithmes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee9a41c-5ef3-4498-88ee-fe4c472b1684",
   "metadata": {},
   "source": [
    "#### **2- Calcul des différentes métriques pour chaque algorithme** \n",
    "\n",
    "Pour éviter la saturation en code dans le notebook, les fonctions \"maison\" de calcul des différentes métriques ainsi que les fonctions d'affichage sont dans le fichier **Outils.py**. Voici le tableau récapitulatif des différentes métriques pour chaque type de descente de gradient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b2e48892-e125-4cb8-895f-0805b5e0b815",
   "metadata": {},
   "source": [
    "# Calcul des métriques (accuracy, precision, recall et F1-score) pour toutes les descentes\n",
    "all_algos_metrics = calculate_all_metrics_for_all(y_test, results_labels)\n",
    "# Affichage\n",
    "display_metrics_dataframe(all_algos_metrics)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "fa42f38c-37ff-4194-9372-6b6c3481aa50",
   "metadata": {},
   "source": [
    "Nos algorithmes montrent de bons résultats sur les différentes métriques, en particulier:\n",
    "\n",
    "- Gradient Descent, Ridge, et Lasso se distinguent avec la meilleure combinaison de précision et de rappel, offrant une F1 Score de quasiment 0.829560, ce qui les rend bien adaptés si on cherche un bon compromis entre ces deux métriques.\n",
    "\n",
    "  \n",
    "- RMSProp est l'algorithme le plus déséquilibré, avec une haute précision mais un rappel très faible.\n",
    "\n",
    "  \n",
    "- SGD, Momentum, Nesterov, AdaGrad, et Adam sont compétitifs, avec des performances relativement similaires, mais Adam se démarque légèrement pour sa robustesse globale.\n",
    "\n",
    "Pour avoir une idée plus claire, voici leurs matrices de confusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2155f8de-adf7-4294-80f4-29f60697993d",
   "metadata": {},
   "source": [
    "plot_confusion_matrices(all_algos_metrics)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "df410594-920f-4d12-8e84-84e76b1a1a3f",
   "metadata": {},
   "source": [
    "Ces résultats sont à interpréter à la lumière de l'objectif. Ici, il est d'identifier de potentiels clients d'un produit financier :\n",
    "\n",
    "- Faux positifs: on prédit qu'un client est intéressé (ou potentiel) alors qu'il ne l'est pas réellement.\n",
    "\n",
    "  \n",
    "Impact : l'entreprise dépense des ressources (temps, argent, efforts marketing) sur des clients qui ne sont finalement pas intéressés. Cela peut représenter un coût financier mais n'a pas d'impact direct sur les opportunités de revenu.\n",
    "\n",
    "- Faux négatifs: on prédit qu'un client n'est pas intéressé, alors qu'il l'est.\n",
    "  \n",
    "Impact : l'entreprise manque une opportunité de convertir un client potentiel, ce qui peut entraîner une perte de revenu. En plus, rater un client revient à renforcer la concurrence qui la capte (effet double).\n",
    "\n",
    "\n",
    "L'erreur à minimiser dans ce contexte est l'erreur de type 2, c'est à dire les faux négatifs. Dans un contexte commercial, cette erreur est souvent plus coûteuse car l'acquisition de nouveaux clients est généralement une priorité. \n",
    "\n",
    "la descente de gradient stochastique montre de très bons résultats pour le recall, tout en gardant un bon compromis f1-score. Elle serait apriori la plus adaptée pour cette problématique.\n",
    "\n",
    "Visualisons sa courbe ROC-AUC :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cc16868e-4841-4a65-af3c-398b4a81e072",
   "metadata": {},
   "source": [
    "# calculer et afficher la courbe ROC-AUC\n",
    "probabilities_sgd = predict(X_test, w_sgd)\n",
    "auc_sgd = plot_roc_curve(y_test, probabilities_sgd)\n",
    "print(f\"AUC pour la descente de gradient stochastique: {auc_sgd:.2f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cd246063-76f6-44e8-8a4b-6b5bf4ec2313",
   "metadata": {},
   "source": [
    "L'aire sous la courbe est de 0,89, ce qui signifie que la probabilité qu'un échantillon positif ait un score prédictif supérieur à celui d'un échantillon négatif, est de 89 % :\n",
    "\n",
    "$\\text{AUC} = P(\\text{Score}_{\\text{positif}} > \\text{Score}_{\\text{négatif}}) = 0{,}89$\n",
    "\n",
    "où :\n",
    "* $P$ représente ici la probabilité.\n",
    "* $\\text{Score}_{\\text{positif}}$ est le score ou la probabilité attribué par le modèle à un échantillon positif.\n",
    "* $\\text{Score}_{\\text{négatif}}$ est le score ou la probabilité attribué à un échantillon négatif.\n",
    "\n",
    "Ce qui représente une performance très acceptable du modèle de descente de gradient stochastique dans cet exercice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b078375a-9914-4d06-b28f-6ede84e5dbd0",
   "metadata": {},
   "source": [
    "## **Conclusion**\n",
    "\n",
    "Cette partie expérimentale sur un dataset réel de marketing bancaire a permis de mettre en pratique et comparer différentes méthodes d'optimisation qu'on a implémenté pour la régression logistique :\n",
    "\n",
    "- Les algorithmes implémentés (descente de gradient simple, stochastique, avec momentum, Nesterov, AdaGrad, RMSprop, Adam, et régularisations Ridge/Lasso) ont tous convergé efficacement, avec des performances légèrement différentes.\n",
    "  \n",
    "- Les méthodes adaptatives (Adam, RMSprop) et celles basées sur le momentum ont montré les meilleures vitesses de convergence.\n",
    "\n",
    "  \n",
    "- Toutes les méthodes ont atteint une précision élevée (> 80%) sur ce jeu de données, la SGD se démarquant légèrement avec le meilleur rappel, et donc la meilleure capacité à minimiser le nombre de faux négatifs.\n",
    "\n",
    "Ce taux élevé de bonnes prédictions est à relativiser certainement par le fait que ça reste un dataset de benchmarking, et qu'il exite probablement des spécificités aux variables choisis qui demanderaient plus de recherches.\n",
    "\n",
    "En tous cas, Ces résultats démontrent l'efficacité des méthodes implémentées et leur capacité à solutionner ce problème complexe qui est l'optimisation d'une fonction de perte. \n",
    "\n",
    "Dans ce travail, le focus a été mis sur une fonction de perte \"Convexe\", sur laquelle les algorithmes d'optimisation, en particulier de descente de gradient restent globalement efficaces et prévisisbles. \n",
    "Cependant, la réalité des problèmes complexes d'apprentissage automatique dépasse souvent ce cadre simple et bien défini. De nombreux modèles performants, tels que les réseaux de neurones profonds, reposent sur des fonctions de perte non convexes, où les défis d'optimisation deviennent nettement plus complexes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
