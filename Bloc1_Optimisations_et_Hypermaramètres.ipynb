{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06234afb-0f8a-45ac-b35b-e1c601ef172c",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "# **Optimisations Par Descente De Gradient,Effet Du Learning-Rate** \n",
    "\n",
    "# **Et Du Batch-Size Sur La Convergence**\n",
    "\n",
    "</div>\n",
    "<br><br>\n",
    "<br><br>\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca1fa60-af44-4811-b4b8-e2e92b7b41cc",
   "metadata": {},
   "source": [
    "## **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1c23e9-3473-44e2-b161-db90e2e2e709",
   "metadata": {},
   "source": [
    "Ce premier Bloc de travail portera sur les optimisations pour la fonction de régression logistique. Il est composé de trois parties. \n",
    "\n",
    "Une première partie sera consacréé à la présentation et l'implémentation des algorithmes d'optimisation usuels pour la fonction de perte \"cross-entropy binaire\".\n",
    "\n",
    "La deuxième et troisième partie traiteront respectivement de l'influence de l'hyperparamètre \"Learning-rate\" et l'hyperparamètre \"Batch-size\" sur la convergence de ces algorithmes.\n",
    "\n",
    "Commençons par un petit rappel du formalisme mathématique de la fonction de **cross-entropy binaire**:\n",
    "\n",
    "Soient :\n",
    "\n",
    "$m$ le nombre d'exemples d'entraînement\n",
    "\n",
    "$x^{(i)}$ le vecteur des caractéristiques pour le i-ème exemple\n",
    "\n",
    "$y^{(i)}$ l'étiquette (0 ou 1) pour le i-ème exemple\n",
    "\n",
    "$\\hat{y}^{(i)}$ la prédiction du modèle pour le i-ème exemple\n",
    "\n",
    "$\\theta$ le vecteur des paramètres du modèle\n",
    "\n",
    "La fonction de perte $J(\\theta)$ est définie comme suit :\n",
    "$$J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^m \\left[ y^{(i)} \\log(\\hat{y}^{(i)}) + (1-y^{(i)}) \\log(1-\\hat{y}^{(i)}) \\right]$$\n",
    "où :\n",
    "$$\\hat{y}^{(i)} = h_\\theta(x^{(i)}) = \\frac{1}{1 + e^{-\\theta^T x^{(i)}}}$$\n",
    "Cette dernière équation est la fonction sigmoïde (ou logistique) appliquée au produit scalaire entre $\\theta$ et $x^{(i)}$.\n",
    "L'objectif de l'apprentissage est de minimiser cette fonction de perte par rapport aux paramètres $\\theta$.\n",
    "La dérivée partielle de la fonction de perte par rapport à un paramètre $\\theta_j$ est :\n",
    "$$\\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i=1}^m (\\hat{y}^{(i)} - y^{(i)}) x_j^{(i)}$$\n",
    "Cette dérivée est utilisée dans l'algorithme de descente de gradient pour mettre à jour les paramètres :\n",
    "$$\\theta_j := \\theta_j - \\alpha \\frac{\\partial J(\\theta)}{\\partial \\theta_j}$$\n",
    "où $\\alpha$ est le pas d'apprentissage.\n",
    "\n",
    "Cette fonction est **Lisse** et **Convexe**, deux proprietés importantes pour les optimisations à venir. La démonstration mathématique de ces deux proprietés est étayée en Annexe-1.\n",
    "\n",
    "\n",
    "Dans la suite, l'implémentation de quelques fonctions nécéssaires à la régression logistique, et la génération des données :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72f8e898-3740-46b7-b072-46f86c9f3fd1",
   "metadata": {},
   "source": [
    "# Implémentation de quelques préalables:\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "np.random.seed(1337)\n",
    "\n",
    "## Définir un set de données adapté à la régression logistique inspiré de l'exemple donné\n",
    "\n",
    "# Paramètres\n",
    "\n",
    "m, n = 1000, 100  # m échantillons, n caractéristiques\n",
    "\n",
    "# Générer des données synthétiques: données d'entrée, coeffs et bruit ajouté\n",
    "\n",
    "X = np.random.normal(0, 1, (m, n)) # On garde une forme sans colonne de biais, c'est un choix pour l'implémentation\n",
    "X_with_bias = np.hstack([np.ones((m, 1)), X]) # pour bien faire le distingo avec un tableau de données X, qui ne contient pas de colonne biais\n",
    "w_opt = np.random.normal(0, 1, n+1) # incluant un biais, d'ou le n+1\n",
    "noise = np.random.normal(0, 0.1, m) # on reste sur le même type de bruit que l'exemple\n",
    "\n",
    "# Obtention des labels à partir des coeffs générés et définis optimaux\n",
    "\n",
    "z = X_with_bias.dot(w_opt) + noise # score brut et bruité (logits)\n",
    "p = 1 / (1 + np.exp(-z))  # Probabilités en sortie de la fonction logistique\n",
    "y =  y = (p >= 0.5).astype(int) # conversion en étiquettes binaires\n",
    "\n",
    "\n",
    "## Quelques fonctions dont nous auront besoin dans l'implémentation\n",
    "\n",
    "# La fonction logistique pour convertir en probabilité la combinaison linéaire des entrées\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Fonction pour initialiser un vecteur de poids de départ ( au hasard, empiriquement efficace)\n",
    "\n",
    "def random_initialize_parameters(n_features):\n",
    "    return np.random.randn(n_features + 1)\n",
    "\n",
    "# Fonction pour prédire la probabilité de l'appartenance à la classe 1 des observations\n",
    "\n",
    "def predict(X, w):\n",
    "    return sigmoid(np.dot(X, w[1:]) + w[0])\n",
    "\n",
    "# Fonction pour calculer la perte logistique, definie en tant que binary cross entropy loss dans ce cas\n",
    "\n",
    "def cost_function(X, y, w, epsilon=1e-8): # notons le rajout d'un petit epsilon pour éviter les divisions par zéro\n",
    "    y_pred = predict(X, w)\n",
    "    cost = - (1 / len(y)) * np.sum(y * np.log(y_pred + epsilon) + (1 - y) * np.log(1 - y_pred + epsilon))\n",
    "    return cost\n",
    "\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "12e41e11-3b15-4dc2-bf6c-d102e911a5cc",
   "metadata": {},
   "source": [
    "## **I- Implémentation des variantes incontournables de la descente de Gradient**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b4ada4-74ee-4694-abf1-5abbcdf3d8f7",
   "metadata": {},
   "source": [
    "### **1- Descente de gradient simple**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "793aab22-b319-4cda-b373-17177e3e69ed",
   "metadata": {},
   "source": [
    "# Implémantation de descente de gradient simple:\n",
    "def gradient_descent(X, y, w_random, learning_rate, num_iterations):\n",
    "    \"\"\"\n",
    "    Implémente l'algorithme de descente de gradient pour la régression logistique.\n",
    "\n",
    "    Args:\n",
    "    X : matrice des caractéristiques (m échantillons par n caractéristiques)\n",
    "    y : vecteur des étiquettes (m échantillons)\n",
    "    w : vecteur initial des poids (n+1 dimensions, incluant le biais)\n",
    "    learning_rate : taux d'apprentissage pour la mise à jour des poids\n",
    "    num_iterations : nombre d'itérations pour l'algorithme\n",
    "\n",
    "    Returns:\n",
    "    w : vecteur final des poids optimisés\n",
    "    costs : liste des coûts à chaque itération\n",
    "    \"\"\"\n",
    "    m = len(y)  # Nombre d'échantillons\n",
    "    costs = []  # Liste pour stocker l'évolution du coût\n",
    "    w = w_random.copy() # pour ne pas altérer les poids d'entrée s'il faut les réutiliser\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        # Calcul des prédictions avec les poids actuels\n",
    "        y_pred = predict(X, w)\n",
    "        \n",
    "        # Calcul du gradient pour les poids (sauf le biais)\n",
    "        dw = (1/m) * np.dot(X.T, (y_pred - y))\n",
    "        # Calcul du gradient pour le biais\n",
    "        db = (1/m) * np.sum(y_pred - y)\n",
    "        \n",
    "        # Mise à jour des poids (sauf le biais) avec la règle de descente de gradient\n",
    "        w[1:] -= learning_rate * dw\n",
    "        # Mise à jour du biais\n",
    "        w[0] -= learning_rate * db\n",
    "        \n",
    "        # Calcul et stockage du coût pour cette itération\n",
    "        cost = cost_function(X, y, w)\n",
    "        costs.append(cost) \n",
    "    return w, costs"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "81ead3fd-1a44-4143-b831-5bc5b7608746",
   "metadata": {},
   "source": [
    "### **2- Descente de gradient stochastique avec taille de batch paramétrable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18e6eb3c-d552-4f9c-9290-2e906fd4c7b3",
   "metadata": {},
   "source": [
    "# Implémentation de la descente de gradient stochastique, extensible en changeant la taille du batch:\n",
    "\n",
    "def stochastic_gradient_descent(X, y, w_random, learning_rate, num_epochs, batch_size=1):\n",
    "    \"\"\"\n",
    "    Implémente l'algorithme de descente de gradient stochastique pour la régression logistique.\n",
    "\n",
    "    Args:\n",
    "    X : matrice des caractéristiques (m échantillons x n caractéristiques)\n",
    "    y : vecteur des étiquettes (m échantillons)\n",
    "    w : vecteur initial des poids (n+1 dimensions, incluant le biais)\n",
    "    learning_rate : taux d'apprentissage pour la mise à jour des poids\n",
    "    num_epochs : nombre d'époques (passages complets sur les données)\n",
    "    batch_size : taille des mini-batchs (1 pour SGD pur, >1 pour mini-batch SGD)\n",
    "\n",
    "    Returns:\n",
    "    w : vecteur final des poids optimisés\n",
    "    costs : liste des coûts à intervalles réguliers\n",
    "    \"\"\"\n",
    "    m = len(y)  # Nombre total d'échantillons\n",
    "    costs = []  # Liste pour stocker l'évolution du coût\n",
    "    w = w_random.copy() # pour ne pas altérer les poids d'entrée s'il faut les réutiliser\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Mélange aléatoire des indices des échantillons\n",
    "        indices = np.random.permutation(m)\n",
    "        X_shuffled = X[indices]\n",
    "        y_shuffled = y[indices]\n",
    "\n",
    "        # Parcours des mini-batchs\n",
    "        for i in range(0, m, batch_size):\n",
    "            # Sélection du mini-batch courant\n",
    "            X_batch = X_shuffled[i:i+batch_size]\n",
    "            y_batch = y_shuffled[i:i+batch_size]\n",
    "\n",
    "            # Calcul des prédictions pour le mini-batch\n",
    "            y_pred = predict(X_batch, w)\n",
    "\n",
    "            # Calcul du gradient pour les poids (sauf le biais) sur le mini-batch\n",
    "            dw = (1/batch_size) * np.dot(X_batch.T, (y_pred - y_batch))\n",
    "            # Calcul du gradient pour le biais sur le mini-batch\n",
    "            db = (1/batch_size) * np.sum(y_pred - y_batch)\n",
    "\n",
    "            # Mise à jour des poids (sauf le biais)\n",
    "            w[1:] -= learning_rate * dw\n",
    "            # Mise à jour du biais\n",
    "            w[0] -= learning_rate * db\n",
    "\n",
    "            # Calcul et stockage du coût\n",
    "            cost = cost_function(X, y, w)\n",
    "            costs.append(cost)\n",
    "\n",
    "    return w, costs"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "16978ef0-08da-4fb8-a0c0-e118050787f8",
   "metadata": {},
   "source": [
    "### **3- Descente de Gradient avec Momentum**\n",
    "\n",
    "La méthode de descente de gradient avec Momentum est une amélioration de la descente de gradient standard qui vise à accélérer la convergence et à réduire les oscillations. Voici le formalisme mathématique qui sous-tend cette méthode :\n",
    "\n",
    "Soient :\n",
    "\n",
    "$\\theta_t$ les paramètres du modèle au temps t\n",
    "\n",
    "$\\nabla J(\\theta_t)$ le gradient de la fonction de coût par rapport aux paramètres au temps t\n",
    "\n",
    "$v_t$ la vélocité au temps t\n",
    "\n",
    "$\\gamma$ le coefficient de momentum (généralement autour de 0.9)\n",
    "\n",
    "$\\eta$ le taux d'apprentissage\n",
    "\n",
    "Les équations de mise à jour pour la descente de gradient avec Momentum sont :\n",
    "\n",
    "Mise à jour de la vélocité :\n",
    "$$v_t = \\gamma v_{t-1} + \\eta \\nabla J(\\theta_t)$$\n",
    "\n",
    "Mise à jour des paramètres :\n",
    "$$\\theta_{t+1} = \\theta_t - v_t$$\n",
    "\n",
    "Dans le contexte de la régression logistique, le gradient $\\nabla J(\\theta)$ est donné par :\n",
    "$$\\nabla J(\\theta) = \\frac{1}{m} X^T (\\hat{y} - y)$$\n",
    "\n",
    "où $\\hat{y} = \\sigma(X\\theta)$ et $\\sigma$ est la fonction sigmoïde.\n",
    "\n",
    "L'intuition derrière le Momentum est qu'il agit comme une \"boule\" roulant le long de la surface de la fonction de coût. La vélocité s'accumule dans les directions qui persistent d'une itération à l'autre, ce qui aide à accélérer la convergence et à surmonter les petits obstacles locaux.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a83b0e3-c338-436a-82f1-20692ff584d8",
   "metadata": {},
   "source": [
    "# Implémentation de la descente de gradient avec Momentum:\n",
    "\n",
    "def gradient_descent_momentum(X, y, w_random, learning_rate, num_iterations, momentum=0.9):\n",
    "    \"\"\"\n",
    "    Implémente l'algorithme de descente de gradient avec Momentum pour la régression logistique.\n",
    "\n",
    "    Args:\n",
    "    X : matrice des caractéristiques (m échantillons x n caractéristiques)\n",
    "    y : vecteur des étiquettes (m échantillons)\n",
    "    w : vecteur initial des poids (n+1 dimensions, incluant le biais)\n",
    "    learning_rate : taux d'apprentissage pour la mise à jour des poids\n",
    "    num_iterations : nombre d'itérations pour l'algorithme\n",
    "    momentum : coefficient de momentum (par défaut 0.9)\n",
    "\n",
    "    Returns:\n",
    "    w : vecteur final des poids optimisés\n",
    "    costs : liste des coûts à chaque itération\n",
    "    \"\"\"\n",
    "    m = len(y)  # Nombre d'échantillons\n",
    "    costs = []  # Liste pour stocker l'évolution du coût\n",
    "    w = w_random.copy() # pour ne pas altérer les poids d'entrée s'il faut les réutiliser\n",
    "    velocity = np.zeros_like(w)  # Initialisation de la vélocité\n",
    "    \n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        # Calcul des prédictions avec les poids actuels\n",
    "        y_pred = predict(X, w)\n",
    "        \n",
    "        # Calcul du gradient\n",
    "        dw = (1/m) * np.dot(X.T, (y_pred - y))\n",
    "        db = (1/m) * np.sum(y_pred - y)\n",
    "        \n",
    "        # Mise à jour de la vélocité\n",
    "        velocity[1:] = momentum * velocity[1:] + learning_rate * dw\n",
    "        velocity[0] = momentum * velocity[0] + learning_rate * db\n",
    "        \n",
    "        # Mise à jour des poids avec la vélocité\n",
    "        w[1:] -= velocity[1:]\n",
    "        w[0] -= velocity[0]\n",
    "        \n",
    "        # Calcul et stockage du coût pour cette itération\n",
    "        cost = cost_function(X, y, w)\n",
    "        costs.append(cost)    \n",
    "    return w, costs"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "6f3630d0-03c4-49d5-b786-db6ad884491a",
   "metadata": {},
   "source": [
    "### **4- Descente de Gradient avec la méthode de Nesterov ( NAG )**\n",
    "\n",
    "La méthode de Nesterov, ou Nesterov Accelerated Gradient (NAG), est une amélioration de la descente de gradient avec Momentum. Elle offre une meilleure convergence en \"anticipant\" la position future des paramètres. Voici le formalisme mathématique de cette méthode :\n",
    "\n",
    "Soient :\n",
    "\n",
    "$\\theta_t$ les paramètres du modèle au temps t\n",
    "\n",
    "$\\nabla J(\\theta)$ le gradient de la fonction de coût par rapport aux paramètres\n",
    "\n",
    "$v_t$ la vélocité au temps t\n",
    "\n",
    "$\\gamma$ le coefficient de momentum (généralement autour de 0.9)\n",
    "\n",
    "$\\eta$ le taux d'apprentissage\n",
    "\n",
    "Les équations de mise à jour pour la méthode de Nesterov sont :\n",
    "\n",
    "Calcul de la position \"anticipée\" :\n",
    "\n",
    "$$\\tilde{\\theta_t} = \\theta_t + \\gamma v_{t-1}$$\n",
    "\n",
    "Calcul du gradient à la position anticipée :\n",
    "\n",
    "$$g_t = \\nabla J(\\tilde{\\theta_t})$$\n",
    "\n",
    "Mise à jour de la vélocité :\n",
    "\n",
    "$$v_t = \\gamma v_{t-1} + \\eta g_t$$\n",
    "\n",
    "Mise à jour des paramètres :\n",
    "\n",
    "$$\\theta_{t+1} = \\theta_t - v_t$$\n",
    "\n",
    "Dans le contexte de la régression logistique, le gradient $\\nabla J(\\theta)$ est calculé de la même manière que pour le Momentum standard, mais à la position anticipée $\\tilde{\\theta_t}$.\n",
    "\n",
    "L'intuition derrière la méthode de Nesterov est qu'elle effectue une correction du gradient basée sur la position future estimée des paramètres, ce qui permet une convergence plus rapide et plus stable que le Momentum standard.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c4843c5-a5a0-42d2-a403-6df5a68c670f",
   "metadata": {},
   "source": [
    "# Implémentation de la descente de gradient avec la méthode de Nesterov:\n",
    "def gradient_descent_nesterov(X, y, w_random, learning_rate, num_iterations, momentum=0.9):\n",
    "    \"\"\"\n",
    "    Implémente l'algorithme de descente de gradient avec la méthode de Nesterov pour la régression logistique.\n",
    "\n",
    "    Args:\n",
    "    X : matrice des caractéristiques (m échantillons x n caractéristiques)\n",
    "    y : vecteur des étiquettes (m échantillons)\n",
    "    w : vecteur initial des poids (n+1 dimensions, incluant le biais)\n",
    "    learning_rate : taux d'apprentissage pour la mise à jour des poids\n",
    "    num_iterations : nombre d'itérations pour l'algorithme\n",
    "    momentum : coefficient de momentum (par défaut 0.9)\n",
    "\n",
    "    Returns:\n",
    "    w : vecteur final des poids optimisés\n",
    "    costs : liste des coûts à chaque itération\n",
    "    \"\"\"\n",
    "\n",
    "    m, n = X.shape\n",
    "    costs = []\n",
    "    w = w_random.copy() # pour ne pas altérer les poids d'entrée s'il faut les réutiliser\n",
    "    velocity = np.zeros_like(w)\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        # Calcul de la position anticipée\n",
    "        w_ahead = w + momentum * velocity\n",
    "        \n",
    "        # Calcul du gradient à la position anticipée\n",
    "        y_pred_ahead = predict(X, w_ahead)\n",
    "        gradient_ahead = np.zeros_like(w)\n",
    "        gradient_ahead[1:] = (1/m) * np.dot(X.T, (y_pred_ahead - y))\n",
    "        gradient_ahead[0] = (1/m) * np.sum(y_pred_ahead - y)\n",
    "        \n",
    "        # Mise à jour de la vélocité avec Nesterov (utilise w_ahead pour le gradient)\n",
    "        velocity = momentum * velocity - learning_rate * gradient_ahead\n",
    "        \n",
    "        # Mise à jour des poids (en appliquant la vélocité)\n",
    "        w += velocity\n",
    "        \n",
    "        # Calcul et stockage du coût\n",
    "        cost = cost_function(X, y, w)\n",
    "        costs.append(cost)\n",
    "\n",
    "    \n",
    "    return w, costs"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9a5344b2-3dac-458e-bb6d-f6900c81c593",
   "metadata": {},
   "source": [
    "### **5- Descente de Gradient Adaptative, AdaGrad**\n",
    "\n",
    "AdaGrad est une méthode d'optimisation qui adapte le taux d'apprentissage individuellement pour chaque paramètre. Elle est particulièrement efficace pour traiter des données éparses et trouve des applications dans de nombreux domaines, notamment le traitement du langage naturel. Voici le formalisme mathématique de cette méthode :\n",
    "\n",
    "Soient :\n",
    "\n",
    "$\\theta_t$ les paramètres du modèle au temps t\n",
    "\n",
    "$g_t = \\nabla J(\\theta_t)$ le gradient de la fonction de coût par rapport aux paramètres au temps t\n",
    "\n",
    "$\\eta$ le taux d'apprentissage initial\n",
    "\n",
    "$\\epsilon$ un petit terme pour éviter la division par zéro (généralement 1e-8)\n",
    "\n",
    "$G_t$ la matrice diagonale où chaque élément i,i est la somme des carrés des gradients par rapport à $\\theta_i$ jusqu'au temps t\n",
    "\n",
    "Les équations de mise à jour pour AdaGrad sont :\n",
    "\n",
    "Accumulation des gradients au carré :\n",
    "\n",
    "$$G_t = G_{t-1} + g_t \\odot g_t$$\n",
    "\n",
    "Mise à jour des paramètres :\n",
    "\n",
    "$$\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{G_t + \\epsilon}} \\odot g_t$$\n",
    "\n",
    "Où $\\odot$ représente la multiplication élément par élément.\n",
    "\n",
    "Dans le contexte de la régression logistique, le gradient $g_t$ est calculé de la même manière que pour les méthodes précédentes :\n",
    "\n",
    "$$g_t = \\frac{1}{m} X^T (\\hat{y} - y)$$\n",
    "\n",
    "où $\\hat{y} = \\sigma(X\\theta)$ et $\\sigma$ est la fonction sigmoïde.\n",
    "\n",
    "L'intuition derrière AdaGrad est qu'il ajuste automatiquement le taux d'apprentissage pour chaque paramètre : les paramètres associés à des caractéristiques fréquentes ou à des gradients importants voient leur taux d'apprentissage diminuer rapidement, tandis que les paramètres associés à des caractéristiques rares ou des gradients faibles conservent un taux d'apprentissage plus élevé.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2902af7c-ef61-4945-b66f-d20ce391bdbb",
   "metadata": {},
   "source": [
    "# Implémentation de la descente de gradient avec AdaGrad:\n",
    "\n",
    "def gradient_descent_adagrad(X, y, w_random, learning_rate, num_iterations, epsilon=1e-8):\n",
    "    \"\"\"\n",
    "    Implémente l'algorithme de descente de gradient avec AdaGrad pour la régression logistique.\n",
    "\n",
    "    Args:\n",
    "    X : matrice des caractéristiques (m échantillons x n caractéristiques)\n",
    "    y : vecteur des étiquettes (m échantillons)\n",
    "    w : vecteur initial des poids (n+1 dimensions, incluant le biais)\n",
    "    learning_rate : taux d'apprentissage initial\n",
    "    num_iterations : nombre d'itérations pour l'algorithme\n",
    "    epsilon : petit terme pour éviter la division par zéro\n",
    "\n",
    "    Returns:\n",
    "    w : vecteur final des poids optimisés\n",
    "    costs : liste des coûts à chaque itération\n",
    "    \"\"\"\n",
    "    m = len(y)  # Nombre d'échantillons\n",
    "    costs = []  # Liste pour stocker l'évolution du coût\n",
    "    w = w_random.copy() # pour ne pas altérer les poids d'entrée s'il faut les réutiliser\n",
    "    G = np.zeros_like(w)  # Initialisation de l'accumulateur de gradients au carré\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        # Calcul des prédictions avec les poids actuels\n",
    "        y_pred = predict(X, w)\n",
    "        \n",
    "        # Calcul du gradient\n",
    "        dw = (1/m) * np.dot(X.T, (y_pred - y))\n",
    "        db = (1/m) * np.sum(y_pred - y)\n",
    "        \n",
    "        # Accumulation des gradients au carré\n",
    "        G[1:] += dw**2\n",
    "        G[0] += db**2\n",
    "        \n",
    "        # Mise à jour des poids\n",
    "        w[1:] -= (learning_rate / (np.sqrt(G[1:] + epsilon))) * dw\n",
    "        w[0] -= (learning_rate / (np.sqrt(G[0] + epsilon))) * db\n",
    "        \n",
    "        # Calcul et stockage du coût pour cette itération\n",
    "        cost = cost_function(X, y, w)\n",
    "        costs.append(cost)\n",
    "  \n",
    "    return w, costs"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "bc321352-76c4-401b-9bef-abeb9c688afc",
   "metadata": {},
   "source": [
    "### **6- Descente de gradient avec RMSprop (Root Mean Square Propagation)**\n",
    "\n",
    "RMSprop est une méthode d'optimisation qui résout certains problèmes d'AdaGrad, notamment la diminution trop rapide du taux d'apprentissage. Elle utilise une moyenne mobile exponentielle des gradients au carré pour normaliser le taux d'apprentissage. Voici le formalisme mathématique de cette méthode :\n",
    "\n",
    "Soient :\n",
    "\n",
    "$\\theta_t$ les paramètres du modèle au temps t\n",
    "\n",
    "$g_t = \\nabla J(\\theta_t)$ le gradient de la fonction de coût par rapport aux paramètres au temps t\n",
    "\n",
    "$\\eta$ le taux d'apprentissage\n",
    "\n",
    "$\\epsilon$ un petit terme pour éviter la division par zéro (généralement 1e-8)\n",
    "\n",
    "$E[g^2]_t$ la moyenne mobile des gradients au carré au temps t\n",
    "\n",
    "$\\beta$ le facteur de décroissance pour la moyenne mobile (généralement 0.9)\n",
    "\n",
    "Les équations de mise à jour pour RMSprop sont :\n",
    "\n",
    "Mise à jour de la moyenne mobile des gradients au carré :\n",
    "\n",
    "$$E[g^2]t = \\beta E[g^2]{t-1} + (1-\\beta) g_t^2$$\n",
    "\n",
    "Mise à jour des paramètres :\n",
    "\n",
    "$$\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{E[g^2]_t + \\epsilon}} \\odot g_t$$\n",
    "\n",
    "Où $\\odot$ représente la multiplication élément par élément.\n",
    "\n",
    "Dans le contexte de la régression logistique, le gradient $g_t$ est calculé de la même manière que pour les méthodes précédentes :\n",
    "\n",
    "$$g_t = \\frac{1}{m} X^T (\\hat{y} - y)$$\n",
    "\n",
    "où $\\hat{y} = \\sigma(X\\theta)$ et $\\sigma$ est la fonction sigmoïde.\n",
    "\n",
    "L'intuition derrière RMSprop est qu'il maintient un taux d'apprentissage adaptatif pour chaque paramètre, mais contrairement à AdaGrad, il utilise une moyenne mobile qui donne plus de poids aux gradients récents. Cela permet d'éviter une diminution trop rapide du taux d'apprentissage et rend l'algorithme plus efficace pour les problèmes non convexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "475e8c01-00a3-45fc-b27b-279da4afadb4",
   "metadata": {},
   "source": [
    "# Implémentation de la descente de gradient avec RMSprop:\n",
    "\n",
    "def gradient_descent_rmsprop(X, y, w_random, learning_rate, num_iterations, beta=0.9, epsilon=1e-8):\n",
    "    \"\"\"\n",
    "    Implémente l'algorithme de descente de gradient avec RMSprop pour la régression logistique.\n",
    "\n",
    "    Args:\n",
    "    X : matrice des caractéristiques (m échantillons x n caractéristiques)\n",
    "    y : vecteur des étiquettes (m échantillons)\n",
    "    w : vecteur initial des poids (n+1 dimensions, incluant le biais)\n",
    "    learning_rate : taux d'apprentissage\n",
    "    num_iterations : nombre d'itérations pour l'algorithme\n",
    "    beta : facteur de décroissance pour la moyenne mobile (par défaut 0.9)\n",
    "    epsilon : petit terme pour éviter la division par zéro\n",
    "\n",
    "    Returns:\n",
    "    w : vecteur final des poids optimisés\n",
    "    costs : liste des coûts à chaque itération\n",
    "    \"\"\"\n",
    "    m = len(y)  # Nombre d'échantillons\n",
    "    costs = []  # Liste pour stocker l'évolution du coût\n",
    "    w = w_random.copy() # pour ne pas altérer les poids d'entrée s'il faut les réutiliser\n",
    "    v = np.zeros_like(w)  # Initialisation de la moyenne mobile des gradients au carré\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        # Calcul des prédictions avec les poids actuels\n",
    "        y_pred = predict(X, w)\n",
    "        \n",
    "        # Calcul du gradient\n",
    "        dw = (1/m) * np.dot(X.T, (y_pred - y))\n",
    "        db = (1/m) * np.sum(y_pred - y)\n",
    "        \n",
    "        # Mise à jour de la moyenne mobile des gradients au carré\n",
    "        v[1:] = beta * v[1:] + (1 - beta) * dw**2\n",
    "        v[0] = beta * v[0] + (1 - beta) * db**2\n",
    "        \n",
    "        # Mise à jour des poids\n",
    "        w[1:] -= (learning_rate / (np.sqrt(v[1:] + epsilon))) * dw\n",
    "        w[0] -= (learning_rate / (np.sqrt(v[0] + epsilon))) * db\n",
    "        \n",
    "        # Calcul et stockage du coût pour cette itération\n",
    "        cost = cost_function(X, y, w)\n",
    "        costs.append(cost)\n",
    "    \n",
    "    return w, costs"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "44c9e2c6-5ffa-4302-b822-8a8319bad14f",
   "metadata": {},
   "source": [
    "### **7- Descente de gradient avec Adam (Adaptive Moment Estimation)**\n",
    "\n",
    "Adam est une méthode d'optimisation qui combine les idées de RMSprop et du Momentum. Elle utilise des estimations du premier et du second moment du \n",
    "\n",
    "gradient pour adapter le taux d'apprentissage de chaque paramètre. Voici le formalisme mathématique de cette méthode :\n",
    "\n",
    "Soient :\n",
    "\n",
    "$\\theta_t$ les paramètres du modèle au temps t\n",
    "\n",
    "$g_t = \\nabla J(\\theta_t)$ le gradient de la fonction de coût par rapport aux paramètres au temps t\n",
    "\n",
    "$\\eta$ le taux d'apprentissage\n",
    "\n",
    "$\\epsilon$ un petit terme pour éviter la division par zéro (généralement 1e-8)\n",
    "\n",
    "$m_t$ l'estimation du premier moment (moyenne) du gradient\n",
    "\n",
    "$v_t$ l'estimation du second moment (variance non centrée) du gradient\n",
    "\n",
    "$\\beta_1, \\beta_2$ les facteurs de décroissance pour les estimations des moments (généralement $\\beta_1 = 0.9, \\beta_2 = 0.999$)\n",
    "\n",
    "Les équations de mise à jour pour Adam sont :\n",
    "\n",
    "Mise à jour des estimations des moments :\n",
    "\n",
    "$$m_t = \\beta_1 m_{t-1} + (1-\\beta_1) g_t$$\n",
    "\n",
    "$$v_t = \\beta_2 v_{t-1} + (1-\\beta_2) g_t^2$$\n",
    "\n",
    "Correction du biais des estimations :\n",
    "\n",
    "$$\\hat{m}_t = \\frac{m_t}{1-\\beta_1^t}$$\n",
    "\n",
    "$$\\hat{v}_t = \\frac{v_t}{1-\\beta_2^t}$$\n",
    "\n",
    "Mise à jour des paramètres :\n",
    "\n",
    "$$\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{\\hat{v}_t} + \\epsilon} \\odot \\hat{m}_t$$\n",
    "\n",
    "Où $\\odot$ représente la multiplication élément par élément.\n",
    "\n",
    "Dans le contexte de la régression logistique, le gradient $g_t$ est calculé de la même manière que pour les méthodes précédentes :\n",
    "\n",
    "$$g_t = \\frac{1}{m} X^T (\\hat{y} - y)$$\n",
    "\n",
    "où $\\hat{y} = \\sigma(X\\theta)$ et $\\sigma$ est la fonction sigmoïde.\n",
    "\n",
    "L'intuition derrière Adam est qu'il combine les avantages du Momentum (qui accélère la convergence dans les directions pertinentes) et de RMSprop (qui adapte le taux d'apprentissage pour chaque paramètre). La correction du biais permet à Adam de fonctionner efficacement même au début de l'optimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49d07efc-bd52-4f5e-8649-bbafb941a40a",
   "metadata": {},
   "source": [
    "# Implémentation de la descente de gradient avec Adam:\n",
    "\n",
    "def gradient_descent_adam(X, y, w_random, learning_rate, num_iterations, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "    \"\"\"\n",
    "    Implémente l'algorithme de descente de gradient avec Adam pour la régression logistique.\n",
    "\n",
    "    Args:\n",
    "    X : matrice des caractéristiques (m échantillons x n caractéristiques)\n",
    "    y : vecteur des étiquettes (m échantillons)\n",
    "    w : vecteur initial des poids (n+1 dimensions, incluant le biais)\n",
    "    learning_rate : taux d'apprentissage\n",
    "    num_iterations : nombre d'itérations pour l'algorithme\n",
    "    beta1 : facteur de décroissance pour l'estimation du premier moment (par défaut 0.9)\n",
    "    beta2 : facteur de décroissance pour l'estimation du second moment (par défaut 0.999)\n",
    "    epsilon : petit terme pour éviter la division par zéro\n",
    "\n",
    "    Returns:\n",
    "    w : vecteur final des poids optimisés\n",
    "    costs : liste des coûts à chaque itération\n",
    "    \"\"\"\n",
    "    m = len(y)  # Nombre d'échantillons\n",
    "    costs = []  # Liste pour stocker l'évolution du coût\n",
    "    w = w_random.copy() # pour ne pas altérer les poids d'entrée s'il faut les réutiliser\n",
    "    m_t = np.zeros_like(w)  # Initialisation de l'estimation du premier moment\n",
    "    v_t = np.zeros_like(w)  # Initialisation de l'estimation du second moment\n",
    "    t = 0  # Initialisation du compteur de temps\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        t += 1  # Incrémentation du compteur de temps\n",
    "        \n",
    "        # Calcul des prédictions avec les poids actuels\n",
    "        y_pred = predict(X, w)\n",
    "        \n",
    "        # Calcul du gradient\n",
    "        dw = (1/m) * np.dot(X.T, (y_pred - y))\n",
    "        db = (1/m) * np.sum(y_pred - y)\n",
    "        \n",
    "        # Mise à jour des estimations des moments\n",
    "        m_t[1:] = beta1 * m_t[1:] + (1 - beta1) * dw\n",
    "        m_t[0] = beta1 * m_t[0] + (1 - beta1) * db\n",
    "        v_t[1:] = beta2 * v_t[1:] + (1 - beta2) * dw**2\n",
    "        v_t[0] = beta2 * v_t[0] + (1 - beta2) * db**2\n",
    "        \n",
    "        # Correction du biais\n",
    "        m_t_hat = m_t / (1 - beta1**t)\n",
    "        v_t_hat = v_t / (1 - beta2**t)\n",
    "        \n",
    "        # Mise à jour des poids\n",
    "        w[1:] -= (learning_rate / (np.sqrt(v_t_hat[1:]) + epsilon)) * m_t_hat[1:]\n",
    "        w[0] -= (learning_rate / (np.sqrt(v_t_hat[0]) + epsilon)) * m_t_hat[0]\n",
    "        \n",
    "        # Calcul et stockage du coût pour cette itération\n",
    "        cost = cost_function(X, y, w)\n",
    "        costs.append(cost)\n",
    "    \n",
    "    return w, costs"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "50e33a3b-8fd1-4282-9383-70e874ee48aa",
   "metadata": {},
   "source": [
    "### **8- Solution quasi analytique, Newton-Raphson**\n",
    "\n",
    "Il est intérressant en dernier lieu d'implémenter la méthode quasi analytique de trouver les coefficiants optimaux.\n",
    "\n",
    "La méthode de Newton-Raphson est une approche quasi-analytique pour optimiser les paramètres de la régression logistique. Elle offre généralement une convergence plus rapide que les méthodes de descente de gradient, surtout près de l'optimum.\n",
    "\n",
    "Soient :\n",
    "\n",
    "- $\\theta_t$ les paramètres du modèle au temps t\n",
    "  \n",
    "- $J(\\theta)$ la fonction de coût (log-vraisemblance négative)\n",
    "  \n",
    "- $\\nabla J(\\theta)$ le gradient de la fonction de coût\n",
    "  \n",
    "- $H(\\theta)$ la matrice Hessienne de la fonction de coût\n",
    "\n",
    "L'équation de mise à jour pour la méthode de Newton-Raphson est :\n",
    "\n",
    "$$\\theta_{t+1} = \\theta_t - [H(\\theta_t)]^{-1} \\nabla J(\\theta_t)$$\n",
    "\n",
    "Pour la régression logistique :\n",
    "\n",
    "- $\\nabla J(\\theta) = X^T(h_\\theta(X) - y)$\n",
    "  \n",
    "- $H(\\theta) = X^T S X$, où $S$ est une matrice diagonale avec $S_{ii} = h_\\theta(x^{(i)})(1 - h_\\theta(x^{(i)}))$\n",
    "\n",
    "\n",
    "La méthode de Newton-Raphson utilise à la fois la première dérivée (gradient) et la seconde dérivée (Hessienne) de la fonction de coût. Cela lui permet de \"sauter\" directement vers le minimum de la fonction, plutôt que de suivre la pente comme dans la descente de gradient.\n",
    "\n",
    "#### Avantages\n",
    "\n",
    "- Convergence quadratique près de l'optimum\n",
    "  \n",
    "- Nécessite généralement moins d'itérations que la descente de gradient\n",
    "\n",
    "#### Inconvénients\n",
    "\n",
    "- Nécessite le calcul et l'inversion de la matrice Hessienne à chaque itération.\n",
    "- Complexité : O(n³) pour n paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d69445bb-cb67-48d3-a115-ae9a54c8adfa",
   "metadata": {},
   "source": [
    "# Implémentation:\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Calcule la fonction sigmoïde.\n",
    "    \n",
    "    Cette implémentation est numériquement stable en limitant les valeurs d'entrée\n",
    "    pour éviter les dépassements.\n",
    "    \n",
    "    Args:\n",
    "    z (numpy.ndarray): Valeurs d'entrée.\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: Sigmoïde des valeurs d'entrée.\n",
    "    \"\"\"\n",
    "    z = np.clip(z, -500, 500)  # Évite le dépassement\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def log_likelihood(X, y, beta):\n",
    "    \"\"\"\n",
    "    Calcule la log-vraisemblance du modèle de régression logistique.\n",
    "    \n",
    "    Cette implémentation utilise des techniques de stabilité numérique.\n",
    "    \n",
    "    Args:\n",
    "    X (numpy.ndarray): Matrice des caractéristiques.\n",
    "    y (numpy.ndarray): Vecteur cible.\n",
    "    beta (numpy.ndarray): Vecteur des coefficients.\n",
    "    \n",
    "    Returns:\n",
    "    float: Valeur de la log-vraisemblance.\n",
    "    \"\"\"\n",
    "    z = X @ beta\n",
    "    z = np.clip(z, -500, 500)  # Évite le dépassement\n",
    "    ll = np.sum(y * z - np.log1p(np.exp(z)))\n",
    "    return ll\n",
    "\n",
    "def gradient(X, y, beta):\n",
    "    \"\"\"\n",
    "    Calcule le gradient de la log-vraisemblance.\n",
    "    \n",
    "    Args:\n",
    "    X (numpy.ndarray): Matrice des caractéristiques.\n",
    "    y (numpy.ndarray): Vecteur cible.\n",
    "    beta (numpy.ndarray): Vecteur des coefficients.\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: Vecteur gradient.\n",
    "    \"\"\"\n",
    "    z = X @ beta\n",
    "    p = sigmoid(z)\n",
    "    grad = X.T @ (p - y)\n",
    "    return grad\n",
    "\n",
    "def hessian(X, y, beta, reg=1e-6):\n",
    "    \"\"\"\n",
    "    Calcule la matrice Hessienne de la log-vraisemblance.\n",
    "    \n",
    "    Cette implémentation inclut une régularisation pour éviter la singularité.\n",
    "    \n",
    "    Args:\n",
    "    X (numpy.ndarray): Matrice des caractéristiques.\n",
    "    y (numpy.ndarray): Vecteur cible.\n",
    "    beta (numpy.ndarray): Vecteur des coefficients.\n",
    "    reg (float): Paramètre de régularisation.\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: Matrice Hessienne.\n",
    "    \"\"\"\n",
    "    z = X @ beta\n",
    "    p = sigmoid(z)\n",
    "    S = p * (1 - p)\n",
    "    H = X.T @ (X * S[:, np.newaxis])\n",
    "    H += reg * np.eye(H.shape[0])  # Ajoute une régularisation pour éviter la singularité\n",
    "    return H\n",
    "\n",
    "def newton_raphson_logistic(X, y, max_iter=100, tol=1e-6):\n",
    "    \"\"\"\n",
    "    Implémente l'algorithme de Newton-Raphson pour la régression logistique.\n",
    "    \n",
    "    Args:\n",
    "    X (numpy.ndarray): Matrice des caractéristiques.\n",
    "    y (numpy.ndarray): Vecteur cible.\n",
    "    max_iter (int): Nombre maximum d'itérations.\n",
    "    tol (float): Tolérance de convergence.\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: Vecteur des coefficients optimisés.\n",
    "    \"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    beta = np.zeros(n_features)\n",
    "    prev_ll = None\n",
    "    lls = []\n",
    "    \n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        grad = gradient(X, y, beta)\n",
    "        hess = hessian(X, y, beta)\n",
    "        \n",
    "        try:\n",
    "            delta = np.linalg.solve(hess, grad)\n",
    "        except np.linalg.LinAlgError:\n",
    "            # Si la Hessienne est singulière, nous utiliserons la pseudo-inverse\n",
    "            delta = np.linalg.pinv(hess) @ grad\n",
    "        \n",
    "        beta -= delta\n",
    "        ll = log_likelihood(X, y, beta)\n",
    "        \n",
    "        # Vérification de la convergence\n",
    "        if prev_ll is not None and abs(ll - prev_ll) < tol:\n",
    "            print(f\"Convergence Newton-Raphson atteinte après {i+1} itérations\")\n",
    "            break\n",
    "        \n",
    "        prev_ll = ll\n",
    "\n",
    "        \n",
    "        lls.append(ll)\n",
    "\n",
    "    \n",
    "    return beta, lls"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8262d9ab-10a9-49d4-b8e5-12421101cfbe",
   "metadata": {},
   "source": [
    "## **II- L'hyperparamètre \"Learning rate\" et la convergence du gradient**\n",
    "\n",
    "Le choix du pas d'apprentissage (learning rate) est crucial dans les algorithmes d'optimisation basés sur la descente de gradient. Un pas trop grand peut entraîner une divergence de l'algorithme, tandis qu'un pas trop petit peut ralentir considérablement la convergence. L'étude de l'influence du pas d'apprentissage sur la convergence est donc essentielle pour comprendre les performances des différents algorithmes et optimiser leur utilisation.\n",
    "\n",
    "Commençons par visualiser les tendances générales de convergence de nos différents algorithmes, dans le cadre d'une fonction de coût convexe et de données de dimensionalité gérable par nos ressources.\n",
    "\n",
    "###     **1- Vision d'ensemble de la réduction de la fonction coût par nos algorithmes, avec un pas non pathologique**\n",
    "\n",
    "Nous allons lancer nos différents algorithmes avec un pas d'apprentissage de 0.05 et observer l'évolution de la fonction coût au fil des itérations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bac60e5c-0e34-4c41-8524-dac56efd85a3",
   "metadata": {},
   "source": [
    "# Fixons nos params\n",
    "\n",
    "learning_rate=0.05\n",
    "max_iter=1000\n",
    "epochs=1\n",
    "batch_size=1 # descente stochastique pure, une observation par mise à jour\n",
    "momentum=0.9\n",
    "epsilon=1e-8 \n",
    "beta1=0.9\n",
    "beta2=0.999\n",
    "w = np.random.normal(0, 1, n+1) # incluant un biais, d'ou le n+1\n",
    "\n",
    "# Reduisons le coût\n",
    "w_gd      , costs_gd      = gradient_descent(X, y, w, learning_rate, max_iter)\n",
    "w_sgd     , costs_sgd     = stochastic_gradient_descent(X, y, w, learning_rate, epochs, batch_size) \n",
    "w_gdm     , costs_gdm     =   gradient_descent_momentum(X, y, w, learning_rate, max_iter, momentum)\n",
    "w_gdn     , costs_gdn     =   gradient_descent_nesterov(X, y, w, learning_rate, max_iter, momentum)\n",
    "w_adagrad , costs_adagrad =    gradient_descent_adagrad(X, y, w, learning_rate, max_iter, epsilon)\n",
    "w_rmsprop , costs_rmsprop =    gradient_descent_rmsprop(X, y, w, learning_rate, max_iter, beta1, epsilon)\n",
    "w_adam    , costs_adam    =       gradient_descent_adam(X, y, w, learning_rate, max_iter, beta1, beta2, epsilon)\n",
    "\n",
    "# Calculons la solution quasi analytique\n",
    "beta, lls = newton_raphson_logistic(X_with_bias, y, max_iter=100, tol=1e-6)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38daad76-58d3-4ba4-b765-6e8cf078ec23",
   "metadata": {},
   "source": [
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "# Courbes des coûts\n",
    "\n",
    "plt.plot(costs_gd, label='Coût descente de gradient simple')\n",
    "plt.plot(costs_sgd, label='Coût gradient stochastique')\n",
    "plt.plot(costs_gdm, label='Coût gradient avec momentum simple ')\n",
    "plt.plot(costs_gdn, label='Coût gradient de Nesterov')\n",
    "plt.plot(costs_adagrad, label='Coût gradient adagrad')\n",
    "plt.plot(costs_rmsprop, label='Coût gradient rmsprop')\n",
    "plt.plot(costs_adam, label='Coût gradient adam')\n",
    "\n",
    "# Légendes\n",
    "plt.xlabel('Itérations')\n",
    "plt.ylabel('Coût')\n",
    "plt.title('Évolution du coût au fil des itérations (1000)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba810035-8a5f-4dc6-b3b7-982720ba81fa",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "# Courbes des coûts\n",
    "\n",
    "plt.plot(costs_gd[:200], label='Coût descente de gradient simple')\n",
    "plt.plot(costs_sgd[:200], label='Coût gradient stochastique')\n",
    "plt.plot(costs_gdm[:200], label='Coût gradient avec momentum simple ')\n",
    "plt.plot(costs_gdn[:200], label='Coût gradient de Nesterov')\n",
    "plt.plot(costs_adagrad[:200], label='Coût gradient adagrad')\n",
    "plt.plot(costs_rmsprop[:200], label='Coût gradient rmsprop')\n",
    "plt.plot(costs_adam[:200], label='Coût gradient adam')\n",
    "\n",
    "# Légendes\n",
    "plt.xlabel('Itérations')\n",
    "plt.ylabel('Coût')\n",
    "plt.title('Évolution du coût sur les 200 premières iterationss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5fb11bc0-2ba1-4b5f-8e0a-6aa3c4eeb2f8",
   "metadata": {},
   "source": [
    "#### Analyse globale\n",
    "\n",
    "- Les méthodes adaptatives (RMSprop, Adam) et celles basées sur le momentum (Momentum simple, Nesterov) montrent les meilleures performances en termes de vitesse de convergence et de coût final atteint.\n",
    "\n",
    "- La descente de gradient stochastique pure (batch_size=1) montre ses limites en termes de stabilité et de vitesse de convergence pour ce problème.\n",
    "Néanmoins elle réalise presque la même performance que la descente de gradient simple en 1000 mises à jour des poids, et ce en ayant calculé l'erreur sur une seule observation du dataset de training à chaque fois. Elle réalise dans ce cas le même résultat que la gradient descent pour un coût computatoire bien moindre et ayant revu 999 fois moins les données.\n",
    "\n",
    "- AdaGrad montre une bonne performance initiale mais ralentit significativement, ce qui est un comportement typique de cette méthode sur de longues périodes d'entraînement.\n",
    "\n",
    "- Le choix du learning_rate (0.05) semble approprié pour la plupart de ces méthodes sur ce dataset, permettant une convergence sans divergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d365676-d2b9-4491-aa05-5d0a9242f768",
   "metadata": {},
   "source": [
    "#### Validité des coefficients obtenus et comparaison de l'accuracy de chaque méthode \n",
    "\n",
    "Nos algorithmes ont bien convergé, mais nous ont ils donné le bon résultat ? C'est à dire les bons coefficients permettant de prédire l'étiquette des données d'entrée. Vérifions cela en prédisant nos étiquettes avec les poids obtenus par chaque méthode. Notre considération ici est juste de savoir si la convergence se fait vers les bonnes cordonnées du coup on utilisera les données d'entrainement par simplification et gain de temps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b933190-bd0d-4ec4-887c-ed6a8c2429b1",
   "metadata": {},
   "source": [
    "# Retrouvons et affichons l'accuracy de chaque méthode, y compris la méthode quasi analytique de Newton-Raphson\n",
    "\n",
    "# Fonction pour étiqueter à partir de probabilités\n",
    "def binary_classification(predictions, threshold=0.5):\n",
    "    return (predictions >= threshold).astype(int)\n",
    "\n",
    "# Générer les prédictions pour chaque méthode\n",
    "y_pred_gd      = predict(X, w_gd)\n",
    "y_pred_sgd     = predict(X, w_sgd)\n",
    "y_pred_gdm     = predict(X, w_gdm)\n",
    "y_pred_gdn     = predict(X, w_gdn)\n",
    "y_pred_adagrad = predict(X, w_adagrad)\n",
    "y_pred_rmsprop = predict(X, w_rmsprop)\n",
    "y_pred_adam    = predict(X, w_adam)\n",
    "y_pred_newton  = predict(X, beta)\n",
    "\n",
    "# Transformer les prédictions en classes binaires \n",
    "y_pred_gd_binary      = binary_classification(y_pred_gd)\n",
    "y_pred_sgd_binary     = binary_classification(y_pred_sgd)\n",
    "y_pred_gdm_binary     = binary_classification(y_pred_gdm)\n",
    "y_pred_gdn_binary     = binary_classification(y_pred_gdn)\n",
    "y_pred_adagrad_binary = binary_classification(y_pred_adagrad)\n",
    "y_pred_rmsprop_binary = binary_classification(y_pred_rmsprop)\n",
    "y_pred_adam_binary    = binary_classification(y_pred_adam)\n",
    "y_pred_newton_binary  = binary_classification(y_pred_newton)\n",
    "\n",
    "# Scores d'accuracy de chaque méthode\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_gd      = accuracy_score(y, y_pred_gd_binary)\n",
    "accuracy_sgd     = accuracy_score(y, y_pred_sgd_binary)\n",
    "accuracy_gdm     = accuracy_score(y, y_pred_gdm_binary)\n",
    "accuracy_gdn     = accuracy_score(y, y_pred_gdn_binary)\n",
    "accuracy_adagrad = accuracy_score(y, y_pred_adagrad_binary)\n",
    "accuracy_rmsprop = accuracy_score(y, y_pred_rmsprop_binary)\n",
    "accuracy_adam    = accuracy_score(y, y_pred_adam_binary)\n",
    "accuracy_newton  = accuracy_score(y, y_pred_newton_binary)\n",
    "\n",
    "# Liste des méthodes et accuracies\n",
    "methods = ['GD', 'SGD', 'GDM', 'NAG', 'AdaGrad', 'RMSProp', 'Adam', 'Newton-Raphson']\n",
    "accuracies = [accuracy_gd, accuracy_sgd, accuracy_gdm, accuracy_gdn, accuracy_adagrad, accuracy_rmsprop, accuracy_adam, accuracy_newton]\n",
    "\n",
    "# Création d'un DataFrame\n",
    "df = pd.DataFrame({'Méthode': methods, 'Accuracy': accuracies})\n",
    "\n",
    "# Configuration du style de seaborn\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"plasma\")\n",
    "\n",
    "# Graphique\n",
    "plt.figure(figsize=(14, 8))\n",
    "ax = sns.barplot(x='Méthode', y='Accuracy', data=df)\n",
    "for i, v in enumerate(df['Accuracy']):\n",
    "    ax.text(i, v + 0.01, f'{v:.4f}', ha='center', va='bottom', fontweight='bold', fontsize=10)\n",
    "plt.title('Comparaison de l\\'Accuracy des Différentes Méthodes d\\'Optimisation', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Méthodes d\\'Optimisation', fontsize=14)\n",
    "plt.ylabel('Accuracy', fontsize=14)\n",
    "y_min = max(0, min(accuracies) - 0.05)\n",
    "y_max = min(1, max(accuracies) + 0.05)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "mean_accuracy = df['Accuracy'].mean()\n",
    "plt.axhline(y=mean_accuracy, color='r', linestyle='--', label=f'Moyenne ({mean_accuracy:.4f})')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Affichage des résultats dans la console\n",
    "print(\"Accuracy des différentes méthodes :\")\n",
    "for method, accuracy in zip(methods, accuracies):\n",
    "    print(f\"{method}: {accuracy:.4f}\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b85e272e-ac6e-4048-8357-942c024eb65e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "  \n",
    "Toutes les méthodes testées montrent d'excellentes performances sur ce dataset simple avec mille itérations. Donc nos algorithmes implémentés font bien le travail qui leur est demandé. Le choix de la méthode optimale dépendra d'autres critères tels que la vitesse de convergence, la stabilité de l'entraînement, et les ressources computationnelles disponibles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0fef92-d18b-49bc-ab5c-e24159fca93f",
   "metadata": {},
   "source": [
    "### **2- Effet du pas d'apprentissage sur la convergence**\n",
    "\n",
    "Dans cette partie, nous allons garder les deux méthodes standards, descente de gradient simple et descente de gradient stochastique. L'idée est d'obtenir l'évolution de la fonction coût avec un pas d'apprentissage dans un intervalle allant de très petit à grand. Le deux graphes qui suivent tracent pour chaque méthode, la courbe d'évolution du coût avec chaque longueur de pas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f82c8117-124c-41ca-a25c-858a6177d0b8",
   "metadata": {},
   "source": [
    "# Définir la plage de valeurs de pas d'apprentissage à tester\n",
    "learning_rates = [ 0.001, 0.01, 0.05, 0.1, 0.5, 1]\n",
    "\n",
    "# Nombre d'itérations\n",
    "num_iterations = 1000\n",
    "batch_size = 1  # SGD pur\n",
    "\n",
    "# Fonction pour tester différents pas d'apprentissage sur la descente de gradient simple et stochastique\n",
    "def test_learning_rates(X, y, w_init, learning_rates, num_iterations):\n",
    "    results_gd = {}\n",
    "    results_sgd = {}\n",
    "    \n",
    "    for lr in learning_rates:\n",
    "        # Descente de gradient simple\n",
    "        w_gd, costs_gd = gradient_descent(X, y, w_init, lr, num_iterations)\n",
    "        results_gd[lr] = costs_gd\n",
    "        # Descente de gradient stochastique\n",
    "        w_sgd, costs_sgd = stochastic_gradient_descent(X, y, w_init, lr, 1, batch_size)\n",
    "        results_sgd[lr] = costs_sgd\n",
    "    return results_gd, results_sgd\n",
    "\n",
    "# Lancer les tests\n",
    "results_gd, results_sgd = test_learning_rates(X, y, w, learning_rates, num_iterations)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27a53ca8-5695-4eaf-b976-bddfd882270e",
   "metadata": {},
   "source": [
    "# Visualiser les résultats\n",
    "def plot_results(results, method_name):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for lr, costs in results.items():\n",
    "        plt.plot(costs[:50], label=f\"Pas d'apprentissage {lr}\")\n",
    "    plt.xlabel('Itérations')\n",
    "    plt.ylabel('Coût')\n",
    "    plt.title(f\"Évolution du coût pour la {method_name} avec différents pas d'apprentissage\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Visualiser les résultats pour la descente de gradient simple\n",
    "plot_results(results_gd, \"descente de gradient simple\")\n",
    "\n",
    "# Visualiser les résultats pour la descente de gradient stochastique\n",
    "plot_results(results_sgd, \"descente de gradient stochastique\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7c59c7f7-50d5-470b-85ee-f4c05216f569",
   "metadata": {},
   "source": [
    "#### Commentaire:\n",
    "\n",
    "Les deux graphes ci-dessus, montrent clairement une influence forte de l'hypermparamètre \"Pas d'apprentissage\" sur la vitesse de convergence et sa stabilité. En effet, avec les mêmes données et la même fonction de perte, une changement de l'amplitude du pas, peut empêcher la fonction de converger ou trop la ralentir. Il peut également produire un comportement erratique d'instabilité, qui se manifeste par des changements abruptes et fréquents du sens de déplacement sur la courbe du coût, au fil des itérations.\n",
    "\n",
    "Afin de mieux saisir les nuances cet effet, essayons de visualiser l'évolution de l'erreur en fonction de l'accroissement du pas d'apprentissage à divers stades de l'apprentissage: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a89a69fc-e4f2-487b-af9b-a402b79862c3",
   "metadata": {},
   "source": [
    "# Numéros d'itérations spécifiques à tracer\n",
    "iteration_points = [1, 5, 10, 100, 1000]\n",
    "\n",
    "# Fonction pour tracer les courbes d'erreurs en fonction du learning_rate\n",
    "def plot_learning_rate_vs_errors(ax, results, method_name):\n",
    "    # Pour chaque point d'itération, on trace la courbe correspondante\n",
    "    for num_iter in iteration_points:\n",
    "        errors = [results[lr][num_iter - 1] if num_iter <= len(results[lr]) else None for lr in learning_rates]\n",
    "        ax.plot(learning_rates, errors, marker='o', label=f'{num_iter} itérations')\n",
    "\n",
    "    ax.set_title(f'Erreur en fonction du learning rate ({method_name})')\n",
    "    ax.set_xlabel('Learning rate')\n",
    "    ax.set_ylabel('Erreur')\n",
    "    ax.set_xscale('log')  # Échelle logarithmique pour mieux visualiser les différences\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "# Créer une figure avec deux sous-graphiques côte à côte\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))  # 1 ligne, 2 colonnes\n",
    "plot_learning_rate_vs_errors(ax1, results_gd, 'Descente de gradient simple')\n",
    "plot_learning_rate_vs_errors(ax2, results_sgd, 'Descente de gradient stochastique')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "10b7b9b0-d170-4fba-a18b-6217033bf201",
   "metadata": {},
   "source": [
    "Nous pouvons distinguer trois cas de figures dans l'ensemble:\n",
    "\n",
    "#### **a- Un pas d'apprentissage sous-évalué (trop faible)**\n",
    "\n",
    "Dans les graphiques, le pas d'apprentissage 0.001 peut être considéré comme trop faible pour les deux méthodes (GD et SGD):\n",
    "\n",
    "- La convergence est lente voire imperceptible : Pour 1000 itérations, l'erreur reste très élevée et autour de l'erreur initiale, alors que d'autres learning rates ont permis de converger déjà.\n",
    "  \n",
    "- La SGD perd son avantage, sa nature stochastique ne procure plus d'avantage significatif avec un pas aussi petit.\n",
    "\n",
    "Avec un pas aussi petit, nous avons des implications pratique de non efficacité: \n",
    "\n",
    "- Temps de calcul excessif : Un pas trop petit nécessite un nombre d'itérations beaucoup plus important pour atteindre la convergence.\n",
    "\n",
    "- Risque de stagnation : L'algorithme peut rester bloqué dans des plateaux ou des régions à faible gradient de la surface de la fonction coût.\n",
    "\n",
    "#### **b- Un pas d'apprentissage sur-évalué (trop élevé)**\n",
    "\n",
    "Dans notre expérience, Les manifestations d'un pas trop élevé sont perceptibles au niveau de l'évolution du coût de la descente stochastique (SGD), ce qui était prévisible. \n",
    "\n",
    "Nous observons par contre que la descente de gradient simple se montre particulièrement robuste, et tire même profit d'une augmentation exagérée du pas d'apprentissage. Cela s'explique par des proprietés intrinsèques et par la nature des données sur lesquelles on travaille:\n",
    "\n",
    "- Fonction de coût convexe et lisse : la log-vraisemblance négative est convexe et lisse. Cela signifie qu'elle n'a qu'un minimum global et pas de minima locaux, et qu'elle a un gradient bien défini qui ne change pas brutalement. Ces deux proprietés offrent des garanties sur la convergence vers un minimum global et sur la stabilité dans la descente.\n",
    "  \n",
    "  ( pour le plaisir, démonstration de la convexité et de la lissité de la log-vraisemblance négative en \"Annexe-1\")\n",
    "\n",
    "- Data issue d'une distribution normale de moyenne 0 et de variance 1 : Cela impacte la pente de la fonction perte en la maintenant à des valeurs modérées, et permettant ainsi une plus grande tolérance à un pas d'apprentissage élevé.\n",
    "  \n",
    "  Dans la théorie de l'optimisation convexe, pour garantir une convergence stable vers un minimum global, Le pas d'apprentissage doit être inférieur à $\\frac{1}{L}$. $L$ étant La constante de **Lipschitz** qui peut être estimée par la norme spectrale maximale de la Hessienne, c'est-à-dire la plus grande valeur propre de la matrice $H(\\theta)$. Dans le cas de la régression logistique, cela donne une estimation de $L$ sous la forme :\n",
    "$$\n",
    "L \\approx \\frac{1}{4} \\max_i ||x_i||^2\n",
    "$$\n",
    "\n",
    "  Avec nos données issues d'une $N(0, 1)$, $||x_i|| \\approx 1$ ce qui est modéré, et notre constante $L \\approx \\frac{1}{4}$ reste elle même modérée. Ainsi l'algorithme peut se permettre des valeurs de pas d'apprentissage plus élevées.\n",
    "\n",
    "  - Autorégulation entre pas d'apprentissage et gradient : en s'approchant du minimum global, la pente s'amoindrit de plus en plus. Le produit du pas d'apprentissage par le gradient reste ainsi dans des marges acceptables et la mise à jour des poids ne fait pas de sauts erratiques.\n",
    "\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745a1c6a-c664-4662-8e07-a8f2495d1b50",
   "metadata": {},
   "source": [
    "<br>\n",
    "C'est au niveau de la descente de gradient stochastique(SGD) que l'ont peut bien distinguer les anomalies induites par un choix de pas d'apprentissage non adapté et exagérément haut. En effet pour les pas de 0.5 et 1 on remarque que l'erreur commence par augmenter, c'est à dire que les mises à jour ne se font pas dans le bon sens. On remarque également qu'à l'instar des tous petits pas, il n'y a pas eu convergence de l'algorithme au bout des milles itérations, avec 0.5 et 1 comme pas d'apprentissage. Nous soulignons égalmement une instabilité qui se manifeste par des oscillations importantes, c'est dire que la recherche du chemin vers le minimum global se fait de façon erratique et avec des sauts pouvant en éloigner.\n",
    "\n",
    "\n",
    "- La vitesse de la convergence : la SGD n'a pas pu profiter d'un gain en début d'entrainement grâce à un grand pas, au contraire elle a été éloignée du minimum global. Ensuite, elle a continué à en patir, sous forme d'une convergence très lente et non garantie, car il est parfaitement possible que l'algorithme diverge avec plus d'itérations. Un pas d'apprentissage trop grand ralentit la vitesse de convergence voire cause la divergence.\n",
    "\n",
    "- Stabilité : Cela se manifeste par des oscillations significatives autour de la direction optimale de descente. Au lieu d'effectuer des mises à jour progressives et cohérentes vers le minimum global, l'algorithme saute d'une région à l'autre de manière erratique, ce qui rend la convergence incertaine. Ces oscillations peuvent entraîner un comportement chaotique de l'algorithme, où les itérations suivantes peuvent annuler en partie les progrès faits précédemment. Ce manque de stabilité complique la trajectoire vers le minimum global, car il est difficile pour l'algorithme de \"se fixer\" sur une bonne direction, le faisant osciller en permanence et potentiellement diverger avec davantage d'itérations.\n",
    "  Une façon de quantifier cette instabilité est d'estimer la variance de l'erreur pour chaque pas d'apprentissage :\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "94e80019-bd55-4268-9b4f-c4c7fa6a081a",
   "metadata": {},
   "source": [
    "# Estimation de l'instabilité par la variance des pertes\n",
    "\n",
    "# Calculer la variance des pertes pour chaque pas d'apprentissage\n",
    "variances_sgd = {lr: np.var(costs) for lr, costs in results_sgd.items()}\n",
    "\n",
    "# Extraire les valeurs des learning rates et les variances pour le plot\n",
    "learning_rates = list(variances_sgd.keys())\n",
    "variances = list(variances_sgd.values())\n",
    "\n",
    "colors = plt.cm.Blues(np.linspace(0.4, 1, len(learning_rates)))\n",
    "colors[2], colors[4] = colors[4], colors[2]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar([str(lr) for lr in learning_rates], variances, color=colors)\n",
    "\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.001, round(yval, 4), ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.title('Variance des pertes en fonction du pas d\\'apprentissage (SGD)', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Pas d\\'apprentissage', fontsize=14)\n",
    "plt.ylabel('Variance des pertes', fontsize=14)\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "77e735bc-d19a-46ee-9147-7f906460b725",
   "metadata": {},
   "source": [
    "    Comme on pouvait s'y attendre, le plus grand pas d'apprentissage a la plus grande variance des valeurs de la perte au fil des itérations. A contrario le plus petit pas est celui qui a la plus petite variance. Cela donne une idée globale, mais une mesure plus révélatrice serait d'estimer la variance des écarts entre pertes successives au fil des itérations, tel que le montre ce graphe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "18fda25c-aa4e-4681-8334-cd0814c31bc1",
   "metadata": {},
   "source": [
    "# Calculer la variance des différences entre pertes successives pour chaque pas d'apprentissage\n",
    "variance_differences_sgd = {lr: np.var(np.diff(costs)) for lr, costs in results_sgd.items()}\n",
    "\n",
    "# Extraire les valeurs des learning rates et les variances pour le plot\n",
    "learning_rates = list(variance_differences_sgd.keys())\n",
    "variance_differences = list(variance_differences_sgd.values())\n",
    "\n",
    "# Tracer un graphique des variances des différences entre pertes successives\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar([str(lr) for lr in learning_rates], variance_differences, color=plt.cm.Blues(np.linspace(0.4, 1, len(learning_rates))))\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.001, round(yval, 4), ha='center', va='bottom', fontsize=12)\n",
    "plt.title('Variance des différences entre pertes successives (SGD)', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Pas d\\'apprentissage', fontsize=14)\n",
    "plt.ylabel('Variance des différences de pertes', fontsize=14)\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3db8f0cc-f999-412a-b0a3-c579ef142b8f",
   "metadata": {},
   "source": [
    "    Avec cette variance, nous pouvons visualiser que les pas de 0.5 et 1 ont les plus grandes variations de valeur de perte d'une itération à une autre et ce malgré un résultat bien loin de l'optimum. Cela s'explique par le comportement instable ou une oscillation peut annuler partiellement ou totalement un gain précédent de descente vers l'optimum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5f4f65-e710-43d7-b5bc-9a4889f1f390",
   "metadata": {},
   "source": [
    "#### **c- Le pas d'apprentissage adapté**\n",
    "\n",
    "- La descente de gradient simple: D'après la théorie présentée précédemment et applicable dans le cas d'une fonction de perte convexe et lisse, nous pouvions avoir la garantie d'une convergence stable avec un pas d'apprentissage allant jusqu'à **$\\frac{1}{L}$**, avec $L$ constante de Lipschitz.\n",
    "\n",
    "  Or avec des données issues d'une distrubtion $N$(0,1) , la valeur de $L$ est appriximée par **$\\frac{1}{4}$**.\n",
    "\n",
    "  Nous pouvons ainsi, théoriquement nous permettre un pas d'apprentissage allant jusqu'à **4**, en étant assurée d'une convergence stable.\n",
    "\n",
    "  Essayons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "99174a6c-1203-4d04-b284-9ce24152e4a8",
   "metadata": {},
   "source": [
    "w_gd_guarantedOptimals,costs_gd_guarantedConvergence_lr = gradient_descent(X, y, w, 4, 1000)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fe1242d5-9cb8-40a0-833d-df2f875f69ec",
   "metadata": {},
   "source": [
    "# Essayons de localiser le critère du coude sur le coût\n",
    "from kneed import KneeLocator\n",
    "\n",
    "\n",
    "costs = costs_gd_guarantedConvergence_lr[:50]  # Remplacez par vos données\n",
    "iterations = range(len(costs))\n",
    "\n",
    "# Utilisation de KneeLocator pour détecter le coude\n",
    "kneedle = KneeLocator(iterations, costs, curve='convex', direction='decreasing')\n",
    "elbow_index = kneedle.elbow\n",
    "\n",
    "# Plotter la courbe des coûts avec le coude\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(iterations, costs, label='Courbe des coûts')\n",
    "plt.axvline(x=elbow_index, color='g', linestyle='--', label=f'Coude à l\\'itération {elbow_index}')\n",
    "plt.scatter(elbow_index, costs[elbow_index], color='b')  # Marquer le point du coude\n",
    "plt.title('Courbe du coût avec un pas à la limite théorique de garantie de convergence (4)')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Coût descente de gradient simple')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Le coude a été détecté à l'itération : {elbow_index}\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "18922e90-9f1e-452c-a11d-3cdecb05748a",
   "metadata": {},
   "source": [
    "Ainsi avec le pas d'apprentissage de 4, la courbe de perte a bel et bien gagné en vitesse de convergence. En plus, elle montre un maximum de gain dans l'amélioration du coût à partir de l'itération 6, ce qui est remarquablement efficace. Ce resultat confirme l'heuristique théorique présentée précédemment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087fb5a4-05a3-4d2c-99e7-347c6d99ba2c",
   "metadata": {},
   "source": [
    "- **Descente de gradient stochastique**: En reprenant le graphique de l'évolution du coût en fonction du pas d'apprentissage et ce à divers stades de l'entrainement, nous nous rendons compte que les grandes valeurs de pas d'apprentissage montrent toutes une tendance haussière du coût. Les petites valeurs de pas montrent toutes une stagnation ou une faible évolution de la perte. Ce qui nous interresse c'est la forme en cuve que prennent au fil de l'augmentation du pas les courbes de coût autour des valeurs 0.05 et 0.1 :\n",
    "\n",
    "  Toutes les courbes atteignent un minimum entre ces deux valeurs de pas. Autrement dit, le pas d'apprentissage efficace, sur ce problème et avec ces données, pour réduire le coût, est situe entre **0.05** et **0.1**\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "067032f6-0095-4682-9a3c-be83453f43c6",
   "metadata": {},
   "source": [
    "# Numéros d'itérations spécifiques à tracer\n",
    "iteration_points = [1, 5, 10, 100, 1000]\n",
    "\n",
    "# Fonction pour tracer les courbes d'erreurs en fonction du learning_rate\n",
    "def plot_learning_rate_vs_errors(ax, results, method_name):\n",
    "    # Pour chaque point d'itération, on trace la courbe correspondante\n",
    "    for num_iter in iteration_points:\n",
    "        errors = [results[lr][num_iter - 1] if num_iter <= len(results[lr]) else None for lr in learning_rates]\n",
    "        ax.plot(learning_rates, errors, marker='o', label=f'{num_iter} itérations')\n",
    "\n",
    "    ax.set_title(f'Erreur en fonction du learning rate ({method_name})')\n",
    "    ax.set_xlabel('Learning rate')\n",
    "    ax.set_ylabel('Erreur')\n",
    "    ax.set_xscale('log')  # Notons bien l'écchelle logarithmique ici pour lisser les distances entre pas \n",
    "    ax.set_xticks(learning_rates)  # Pour afficher les valeurs du learning rate sur les abscisses\n",
    "    ax.set_xticklabels([f'{lr:.0e}' for lr in learning_rates])  # Formatage des labels en notation scientifique si nécessaire\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "# Créer une figure avec un seul graphique pour la descente de gradient stochastique\n",
    "fig, ax = plt.subplots(figsize=(7, 6))  # Taille ajustée pour un seul graphique\n",
    "plot_learning_rate_vs_errors(ax, results_sgd, 'Descente de gradient stochastique')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "74778078-edf0-4904-8cd6-629ec913f698",
   "metadata": {},
   "source": [
    "## **III- L'hyperparamètre \"Batch-size\" et la convergence du gradient stochastique**\n",
    "\n",
    "Le Batch size est le nombre d'exemples que l'algorithme prend en compte pour évaluer sa prochaine mise à jour des poids. Autrement dit, de la quantité de données à prendre en compte avant de décider de la direction du prochain pas de recherche du point le optimal de la fonction de coût. \n",
    "\n",
    "Dans la phase de tests initiaux, nous avons vu que la descente de gradient stochastique pure, sur cette fonction de perte convexe et lisse, réalisait à nombre de mises à jours égales (1000 déplacements) et en prenant une observation à la fois, quasiment la même performance qu'une descente de gradient simple qui aura revu le training-set 999 fois supplémentaires. Cela était un argument fort pour se pencher sur ce paramètre et essayer d'évaluer son rôle dans la descente de gradient d'un point de vue de l'optimisation.\n",
    "\n",
    "Dans un premier temps, intérressons nous à mener l'expérience de tester diverses valeurs de batch-size et d'observer l'effet de changement de la taille de batch sur la courbe de perte à nombre de mises à jours égales.\n",
    "\n",
    "Le pas d'apprentissage de 0.1 sera adopté d'après nos observations de la section précédente.\n",
    "\n",
    "Dans cette expérience, et vue l'implémentation de la fonction gradient stochastique, le paramètre batch_size sera égal au paramètre epoch, cette égalité permettera un nombre d'itérations constant pour toutes les valeurs de batch-size essayées.\n",
    "\n",
    "en effet :\n",
    "\n",
    "$$\\text{Nombre d'itérations} = \\frac{N}{\\text{batch\\_size}} \\times \\text{epochs}$$\n",
    "\n",
    "Nous adopterons des valeurs de batch-size appartenant aux diviseurs de la taille du dataset $\\left\\{1,2,4, ...,250,\\frac{N}{2}\\right\\}$, pour ne pas prendre le risque d'avoir un dernier batch traité qui soit d'une taille inférieure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5b17a18f-06ff-41ec-b48f-63f1f6269a9e",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Paramètres de l'expérience \"descente de gradient stochastique avec différents batchs-size\"\n",
    "\n",
    "learning_rate = 0.1\n",
    "w_initial = w.copy()  # toujours faire une copie pour garderla matrice d'initialisation intacte\n",
    "batch_sizes = [1,2,4,8,20,40,100,200,250,500]  # Différentes valeurs de batch_size dans les diviseurs de N\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Boucle de calcul des coûts pour chaque taille de batch\n",
    "for batch_size in batch_sizes:\n",
    "    num_epochs = batch_size # dans ce cas, ca conserve bien le même nombre d'itérations\n",
    "    print(f\"\\n\\nExécution pour num_epochs = {num_epochs}, batch_size = {batch_size}\")\n",
    "    \n",
    "    w_opt, costs = stochastic_gradient_descent(X, y, w_initial, learning_rate, num_epochs, batch_size)\n",
    "    \n",
    "    # Stockage des résultats pour cette combinaison\n",
    "    results[batch_size] = {\n",
    "        \"weights\": w_opt,\n",
    "        \"costs\": costs\n",
    "    }\n",
    "    print(f\"Coût final : {costs[-1]}\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bb1d5143-fdaa-4a50-80ae-754f4d484198",
   "metadata": {},
   "source": [
    "# Maintenant, traçons les courbes de perte\n",
    "plt.figure(figsize=(10, 6))\n",
    "for batch_size in batch_sizes:\n",
    "    costs = results[batch_size][\"costs\"][:1000]\n",
    "    plt.plot(costs, label=f'Batch size: {batch_size}')\n",
    "plt.title(\"Évolution de la perte pour différentes tailles de batch\")\n",
    "plt.xlabel(\"Itérations\")\n",
    "plt.ylabel(\"Coût\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "646e89a4-eb51-4013-975e-8b95e1108012",
   "metadata": {},
   "source": [
    "Nos descentes ont bel et bien convergé pour les différentes valeurs de batch.\n",
    "\n",
    "Néanmoins nous remarquons une différenciation en deux groupe:\n",
    "\n",
    "- Pour un batch size de 1 et 2, la vitesse de convergence est moins rapide et la descente instable, en particulier pour la descente de gradient pure qui de surcroit converge vers un optimum significativement plus élevé que les autres.\n",
    "  \n",
    "- A partir d'une taille de batch de 4 (soit 0.4 % de la taille du dataset), une stabilité d'installe avec une vitesse de convergence qui semble proche voir équivalente.\n",
    "\n",
    "Essayons de visualiser les itérations auxquelles 90 % de la perte a été réduite. Plottons les en fonction de la taille de batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "84c90106-d3ba-449d-89fd-f9196c1c91dd",
   "metadata": {},
   "source": [
    "\n",
    "# Fonction pour calculer où un certain pourcentage de la perte initiale est atteint\n",
    "def find_percentage_loss_point(costs, percentage):\n",
    "    initial_loss = costs[0]\n",
    "    target_loss = initial_loss * ((100 - percentage) / 100)  # Calcul du pourcentage de réduction de la perte\n",
    "    for i, cost in enumerate(costs):\n",
    "        if cost <= target_loss:\n",
    "            return i\n",
    "    return None  # Si le point n'est pas trouvé\n",
    "\n",
    "# Choisir un pourcentage pour calculer le point de descente\n",
    "percentage = 90  \n",
    "\n",
    "# Calcul des points où le pourcentage de la perte initiale est atteint\n",
    "loss_percentage_points = {}\n",
    "for batch_size in batch_sizes:\n",
    "    costs = results[batch_size][\"costs\"][:1000]\n",
    "    # Trouver le point où le pourcentage de la perte initiale est atteint\n",
    "    point_percentage = find_percentage_loss_point(costs, percentage)\n",
    "    loss_percentage_points[batch_size] = point_percentage\n",
    "\n",
    "# Plotter\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# Premier graphique : courbes de coût originales avec points où le pourcentage de perte initiale est atteint\n",
    "for batch_size in batch_sizes:\n",
    "    # Tracer les vraies valeurs de la courbe (non lissées)\n",
    "    costs = results[batch_size][\"costs\"][:1000]\n",
    "    ax1.plot(costs, label=f'Batch size: {batch_size}')\n",
    "\n",
    "    # Si le point où le pourcentage de la perte initiale est atteint est trouvé, l'afficher sur la courbe non lissée\n",
    "    if loss_percentage_points[batch_size] is not None:\n",
    "        iteration_percentage = loss_percentage_points[batch_size]\n",
    "        ax1.scatter(iteration_percentage, costs[iteration_percentage], marker='o', s=100, \n",
    "                    label=f'{percentage}% descente (Batch size: {batch_size})')\n",
    "        \n",
    "\n",
    "\n",
    "ax1.set_title(f\"Évolution de la perte avec points de descente à {percentage}% de la perte initiale\")\n",
    "ax1.axhline(y=0.366, color='black', linestyle='--', label='y = 0.366 (10% de perte restante)')\n",
    "ax1.set_xlabel(\"Itérations\")\n",
    "ax1.set_ylabel(\"Coût\")\n",
    "ax1.legend()\n",
    "\n",
    "# Deuxième graphique : points où le pourcentage de la perte est atteint en fonction de la taille du batch\n",
    "batch_sizes_list = list(batch_sizes)\n",
    "loss_percentage_iterations = [loss_percentage_points[bs] if loss_percentage_points[bs] is not None else np.nan for bs in batch_sizes_list]\n",
    "\n",
    "ax2.plot(batch_sizes_list, loss_percentage_iterations, marker='o')\n",
    "ax2.set_title(f\"Numéro d'Itération à {percentage}% de la perte initiale en fonction de la taille du batch\")\n",
    "ax2.set_xlabel(\"Taille du batch\")\n",
    "ax2.set_ylabel(f\"Itération à {percentage}% de perte initiale\")\n",
    "ax2.set_xticks(batch_sizes_list)\n",
    "ax2.set_xticklabels(batch_sizes_list, rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Afficher les valeurs numériques des points où le pourcentage de la perte est atteint\n",
    "for bs, iteration in loss_percentage_points.items():\n",
    "    if iteration is not None:\n",
    "        print(f\"Batch size: {bs}, {percentage}% de réduction de l'erreur à l'itération {iteration}\")\n",
    "    else:\n",
    "        print(f\"Batch size: {bs}, {percentage}% de réduction non atteinte dans les 1000 premières itérations\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9064c159-19dc-4204-98e0-f32ba2c854d9",
   "metadata": {},
   "source": [
    "Le graphe ci-dessus montre une décroissance très rapide du nombre d'itérations nécessaires à la réduction de 90% de l'erreur, quand on augmente la taille du batch. Nous passons de 396 itérations nécéssaires avec la stochastique pure (batch-size = 1), à 284 itérations avec deux échantillons pris à la fois, pour ensuite atteindre 211 itérations avec une taille de batch de 8. Le gain en rapidité stagne après.\n",
    "\n",
    "Visualisons  le classement des tailles de batch par ordre décroissant de rapidité à réduire l'erreur de 90%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fbd56abb-13a2-4193-abec-01002f666809",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Trier les tailles de batch en fonction de l'itération où 90 % de la perte est atteinte\n",
    "sorted_batch_sizes = sorted(loss_percentage_points, key=lambda x: loss_percentage_points[x] if loss_percentage_points[x] is not None else float('inf'))\n",
    "\n",
    "# Créer un graphique en barre pour visualiser le classement\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "sorted_iterations = [loss_percentage_points[bs] for bs in sorted_batch_sizes]\n",
    "\n",
    "# Affichage des barres avec les numéros d'itération\n",
    "bars = ax.bar(range(len(sorted_batch_sizes)), sorted_iterations, color='skyblue')\n",
    "\n",
    "# Ajouter les numéros d'itération au-dessus des barres\n",
    "for bar, iteration in zip(bars, sorted_iterations):\n",
    "    if iteration is not None:\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{int(iteration)}',\n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Ajouter des titres et des labels\n",
    "ax.set_title(f\"Classement des tailles de batch par rapidité à réduire l'erreur de {percentage}% \", fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel(\"Taille du batch\", fontsize=12)\n",
    "ax.set_ylabel(f\"Itération qui permet {percentage}% de réduction de la perte\", fontsize=12)\n",
    "ax.set_xticks(range(len(sorted_batch_sizes)))\n",
    "ax.set_xticklabels(sorted_batch_sizes, fontsize=12)\n",
    "\n",
    "# Ajouter une grille pour plus de lisibilité\n",
    "ax.grid(True, linestyle='--', linewidth=0.7, alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "591c48c0-14d8-4733-8c67-19fae9dd95cf",
   "metadata": {},
   "source": [
    "Les valeurs de batch-size ayant donné les descentes les plus lentes (en nombre d'itérations), sont la taille 1 et 2.\n",
    "\n",
    "En augmentant la taille de batch au delà, la vitesse de réduction de 90 % de l'erreur stagne entre 211 et 217 itérations. Cela suggère que sur cet ensemble de données et avec les différents paramètres pris, il serait non nécéssaire d'aller au delà d'une taille de 4 échantillons pour le batch-size si l'on considère juste la réduction du risque empirique et l'économie computationnelle. Car en effet, rappelons nous qu'à performance quasi égale, la descente avec un batch-size de 500, a eu un besoin de revoir les données 125 fois supérieur à celui de la descente avec un batch size de 4.\n",
    "\n",
    "Pour avoir une idée de ce coût computationnel qui augmente avec le nombre d'epochs, voici une implémentation naive de la fonction descente de gradient stochastique intégrant un compteur simpliste de d'opérations flottantes \"FLOPS\", qui s'interresse essentiellement aux opéreations matricielles et qui ignore les optimisations possibles. Quand on applique la descente avec un nombre d'itérations identique mais avec diverses valeurs de batch-size, nous obtenons l'ordre de croissance suivant du coût computationnel en Flops:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8955ce08-0abe-43ad-944a-6a2f3b5a4948",
   "metadata": {},
   "source": [
    "# Implémentation naive d'un compteur de FLOPs \n",
    "def stochastic_gradient_descent_flops(X, y, w_random, learning_rate, num_epochs, batch_size=1):\n",
    "    \"\"\"\n",
    "    Implémente l'algorithme de descente de gradient stochastique pour la régression logistique avec un \n",
    "    compteur de FLOPs.\n",
    "\n",
    "    Args:\n",
    "    X : matrice des caractéristiques (m échantillons x n caractéristiques)\n",
    "    y : vecteur des étiquettes (m échantillons)\n",
    "    w : vecteur initial des poids (n+1 dimensions, incluant le biais)\n",
    "    learning_rate : taux d'apprentissage pour la mise à jour des poids\n",
    "    num_epochs : nombre d'époques (passages complets sur les données)\n",
    "    batch_size : taille des mini-batchs (1 pour SGD pur, >1 pour mini-batch SGD)\n",
    "\n",
    "    Returns:\n",
    "    w : vecteur final des poids optimisés\n",
    "    costs : liste des coûts à intervalles réguliers\n",
    "    total_flops : nombre total de FLOPs effectuées\n",
    "    \"\"\"\n",
    "    m, n = X.shape  # m: nombre total d'échantillons, n: nombre de caractéristiques\n",
    "    costs = []  # Liste pour stocker l'évolution du coût\n",
    "    w = w_random.copy()  # Pour ne pas altérer les poids d'entrée s'il faut les réutiliser\n",
    "    \n",
    "    total_flops = 0  # Compteur de FLOPs\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Mélange aléatoire des indices des échantillons\n",
    "        indices = np.random.permutation(m)\n",
    "        X_shuffled = X[indices]\n",
    "        y_shuffled = y[indices]\n",
    "\n",
    "        # Parcours des mini-batchs\n",
    "        for i in range(0, m, batch_size):\n",
    "            # Sélection du mini-batch courant\n",
    "            X_batch = X_shuffled[i:i+batch_size]\n",
    "            y_batch = y_shuffled[i:i+batch_size]\n",
    "\n",
    "            # FLOPs pour calculer les prédictions : produit matrice-vecteur\n",
    "            # Nombre d'opérations pour un produit matrice-vecteur est 2 * batch_size * n\n",
    "            y_pred = predict(X_batch, w)\n",
    "            total_flops += 2 * batch_size * n\n",
    "\n",
    "            # FLOPs pour calculer les gradients : produit matrice-transposée et soustraction\n",
    "            # Nombre d'opérations pour le gradient : 2 * n * batch_size pour le produit X.T @ (y_pred - y_batch)\n",
    "            dw = (1 / batch_size) * np.dot(X_batch.T, (y_pred - y_batch))\n",
    "            total_flops += 2 * batch_size * n\n",
    "\n",
    "            # FLOPs pour la somme des erreurs : n additions pour la somme des différences\n",
    "            db = (1 / batch_size) * np.sum(y_pred - y_batch)\n",
    "            total_flops += batch_size  # On compte une addition par échantillon dans le batch\n",
    "\n",
    "            # Mise à jour des poids : n multiplications et n additions pour chaque mise à jour de w\n",
    "            w[1:] -= learning_rate * dw\n",
    "            total_flops += 2 * n  # n multiplications et n additions\n",
    "            w[0] -= learning_rate * db\n",
    "            total_flops += 2  # 1 multiplication et 1 addition pour le biais\n",
    "\n",
    "            # Calcul et stockage du coût : coût sur tout le batch\n",
    "            cost = cost_function(X, y, w)\n",
    "            costs.append(cost)\n",
    "            #total_flops += batch_size * n  # exclu en démonstration\n",
    "\n",
    "    return w, costs, total_flops"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "594f380f-ad1c-4d8e-89b6-4eebc4b28f73",
   "metadata": {},
   "source": [
    "# Calcul du coût computationnel, à nombre d'itérations égale et batch-size croissant\n",
    "\n",
    "learning_rate = 0.1\n",
    "w_initial = w.copy()  \n",
    "batch_sizes = [1,2,4,8,20,40,100,200,250,500]  # Différentes valeurs de batch_size dans les diviseurs de N\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Boucle de calcul des coûts pour chaque taille de batch\n",
    "for batch_size in batch_sizes:\n",
    "    num_epochs = batch_size # dans ce cas, ca conserve bien le même nombre d'itérations\n",
    "    print(f\"\\n\\nExécution pour num_epochs = {num_epochs}, batch_size = {batch_size}\")\n",
    "    \n",
    "    w_opt, costs, total_flops = stochastic_gradient_descent_flops(X, y, w_initial, learning_rate, num_epochs, batch_size)\n",
    "    \n",
    "    # Stockage des résultats pour cette combinaison\n",
    "    results[batch_size] = {\n",
    "        \"weights\": w_opt,\n",
    "        \"costs\": costs,\n",
    "        \"total_flops\" : total_flops\n",
    "    }\n",
    "    print(f\" Total Flops  : {total_flops}\")\n",
    "    "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9941d520-53f6-4095-85a3-7f440bec767a",
   "metadata": {},
   "source": [
    "batch_sizes_list = list(results.keys())\n",
    "flops_values = [results[batch_size]['total_flops'] for batch_size in batch_sizes_list]\n",
    "\n",
    "# Tracer le coût computatoire en fonction du nombre d'epochs\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(batch_sizes_list, flops_values, marker='o', linestyle='-', color='b')\n",
    "plt.title(\"Ordre de croissance du coût computationnel \", fontsize=14)\n",
    "plt.xlabel(\"epochs\", fontsize=12)\n",
    "plt.ylabel(\"FLOPs\", fontsize=12)\n",
    "plt.xlim(-20,600)\n",
    "plt.ylim(-0.1e08,2.5e08)\n",
    "log_batch_sizes = np.log(batch_sizes_list)\n",
    "log_flops_values = np.log(flops_values)\n",
    "coefficients = np.polyfit(log_batch_sizes, log_flops_values, 1)\n",
    "slope, intercept = coefficients\n",
    "plt.text(0.5, 0.1, f\"Pente : {slope:.2f}\", fontsize=12, transform=plt.gca().transAxes)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "bd3f7c28-e6eb-49a5-96a9-8d3d37afdfa4",
   "metadata": {},
   "source": [
    "Ce résultat renforce notre intuition, qu'à performances égales, il serait préférable de se tourner vers le batchs-size de petite taille qui auront un coût computationnel moindre. Plus généralement, un batch size de plus petite taille offre également une plus grande capacité à échapper aux minima locaux, sans parler du coût en mémoire."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce500ee-81ef-4e2c-97eb-404467517d01",
   "metadata": {},
   "source": [
    "En tenant compte de ces résultats, l'idée est de savoir comment identifier facilement la taille de batch-size idéale offrant les meilleures performances. L'état actuel de la recherche ne tranche pas la question, \n",
    "qui dépend de plusieurs facteurs, notamment le dataset, le modèle, la fonction de perte et les ressources matérielles disponibles.\n",
    "\n",
    "Il existe néanmoins de règles empiriques ayant montré une certaine efficacité:\n",
    "\n",
    "- Favoriser les puissance de 2 pour l'exploration\n",
    "\n",
    "- Une batch-size de départ = $\\sqrt{N}$ avec $N$ le nombre d'échantillons, et en restant en dessous de 512.\n",
    "\n",
    "- Exploration sur un petit nombre d'itérations, en essayant de borner par dichotomie à chaque fois.\n",
    "\n",
    "\n",
    "Nous pouvons imaginer une fonction qui détermine le batch-size permettant la vitesse de convergence la plus rapide, sur un nombre limité d'iérations, avec des contraintes de limite de variance acceptable, et en appliquant les différentes heuristiques évoquées:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "749f3ce6-44c7-4e6e-84f3-936dd100c4a1",
   "metadata": {},
   "source": [
    "# Fonction de recherche de batch-size idéale qui se sert de règles empiriques citées ci_dessus\n",
    "\n",
    "def find_optimal_batch_size(X, y, w_random, learning_rate, acceptable_variance=1e-3, max_iterations=100):\n",
    "    \"\"\"\n",
    "    Trouve la taille de batch optimale en explorant les puissances de 2 entre 2 et sqrt(m), par dichotomie.\n",
    "    Le critère de séléction est la vitesse de réduction de l'erreur\n",
    "\n",
    "    Args:\n",
    "    X : matrice des caractéristiques (m échantillons x n caractéristiques)\n",
    "    y : vecteur des étiquettes (m échantillons)\n",
    "    w_random : vecteur initial des poids (n+1 dimensions, incluant le biais)\n",
    "    learning_rate : taux d'apprentissage pour la mise à jour des poids\n",
    "    acceptable_variance : variance acceptable du coût pour considérer la convergence stable\n",
    "    max_iterations : nombre maximal d'itérations, de mises à jours des poids.\n",
    "\n",
    "    Returns:\n",
    "    optimal_batch_size : la taille de batch optimale trouvée\n",
    "    batch_size_costs : dictionnaire contenant les coûts finaux pour chaque taille de batch testée\n",
    "    \"\"\"\n",
    "    m = len(y)\n",
    "\n",
    "    # Définir la taille de batch initiale comme la puissance de 2 la plus proche de sqrt(m)\n",
    "    initial_exponent = int(np.floor(np.log2(np.sqrt(m))))\n",
    "    initial_batch_size = 2 ** initial_exponent \n",
    "    \n",
    "\n",
    "    # Limites pour la dichotomie\n",
    "    lower_exponent = 1  # Correspond à une taille de batch de 2^1 = 2\n",
    "    upper_exponent = initial_exponent\n",
    "\n",
    "    batch_size_costs = {}\n",
    "\n",
    "    for iteration in range(max_iterations):\n",
    "        # Calculer la taille de batch moyenne\n",
    "        mid_exponent = (lower_exponent + upper_exponent) // 2\n",
    "        batch_sizes = [2 ** exp for exp in [lower_exponent, mid_exponent, upper_exponent]]\n",
    "        batch_sizes = sorted(set(batch_sizes))  # Éviter les doublons\n",
    "\n",
    "        for batch_size in batch_sizes:\n",
    "            if batch_size in batch_size_costs:\n",
    "                continue  # Déjà évalué\n",
    "\n",
    "            # Exécuter la descente de gradient stochastique avec cette taille de batch\n",
    "            w = w_random.copy()\n",
    "            num_epochs = batch_size\n",
    "            w, costs = stochastic_gradient_descent_recherche_optimum(\n",
    "                X, y, w, learning_rate, num_epochs, batch_size, max_iterations\n",
    "            )\n",
    "\n",
    "            # Calculer la variance du coût sur les dernières itérations\n",
    "            recent_costs = costs[-10:] if len(costs) >= 10 else costs\n",
    "            cost_variance = np.var(recent_costs)\n",
    "\n",
    "            # Stocker le coût final et la variance\n",
    "            batch_size_costs[batch_size] = {\n",
    "                'final_cost': costs[-1],\n",
    "                'cost_variance': cost_variance\n",
    "            }\n",
    "\n",
    "        # Trouver la taille de batch avec le coût final le plus bas\n",
    "        optimal_batch_size = min(\n",
    "            batch_size_costs, key=lambda k: batch_size_costs[k]['final_cost']\n",
    "        )\n",
    "\n",
    "        # Vérifier si la variance est acceptable\n",
    "        if batch_size_costs[optimal_batch_size]['cost_variance'] <= acceptable_variance:\n",
    "            print(f\"Taille de batch optimale trouvée: {optimal_batch_size}\")\n",
    "            break\n",
    "\n",
    "        # Mise à jour des limites pour la dichotomie\n",
    "        if optimal_batch_size == 2 ** lower_exponent:\n",
    "            upper_exponent = mid_exponent - 1\n",
    "        elif optimal_batch_size == 2 ** upper_exponent:\n",
    "            lower_exponent = mid_exponent + 1\n",
    "        else:\n",
    "            lower_exponent = mid_exponent\n",
    "            upper_exponent = mid_exponent\n",
    "\n",
    "        # S'assurer que les exposants restent valides\n",
    "        lower_exponent = max(lower_exponent, 1)\n",
    "        upper_exponent = max(upper_exponent, 1)\n",
    "\n",
    "        if lower_exponent >= upper_exponent:\n",
    "            print(f\"Limite atteinte avec la taille de batch: {optimal_batch_size}\")\n",
    "            break\n",
    "\n",
    "    return optimal_batch_size, batch_size_costs\n",
    "\n",
    "def stochastic_gradient_descent_recherche_optimum(X, y, w_random, learning_rate, num_epochs, batch_size=1,max_iterations=100):\n",
    "   \n",
    "    m = len(y)  # Nombre total d'échantillons\n",
    "    costs = []  # Liste pour stocker l'évolution du coût\n",
    "    w = w_random.copy()  # Pour ne pas altérer les poids d'entrée s'il faut les réutiliser\n",
    "\n",
    "    total_iterations = 0  # Compteur pour le nombre total d'itérations\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Mélange aléatoire des indices des échantillons\n",
    "        indices = np.random.permutation(m)\n",
    "        X_shuffled = X[indices]\n",
    "        y_shuffled = y[indices]\n",
    "\n",
    "        # Parcours des mini-batchs\n",
    "        for i in range(0, m, batch_size):\n",
    "            # Vérifier si le nombre maximal d'itérations est atteint\n",
    "            if total_iterations >= num_epochs * (m // batch_size):\n",
    "                break\n",
    "\n",
    "            # Sélection du mini-batch courant\n",
    "            X_batch = X_shuffled[i:i+batch_size]\n",
    "            y_batch = y_shuffled[i:i+batch_size]\n",
    "\n",
    "            # Calcul des prédictions pour le mini-batch\n",
    "            y_pred = predict(X_batch, w)\n",
    "\n",
    "            # Calcul du gradient pour les poids (sauf le biais) sur le mini-batch\n",
    "            dw = (1 / len(y_batch)) * np.dot(X_batch.T, (y_pred - y_batch))\n",
    "            # Calcul du gradient pour le biais sur le mini-batch\n",
    "            db = (1 / len(y_batch)) * np.sum(y_pred - y_batch)\n",
    "\n",
    "            # Mise à jour des poids (sauf le biais)\n",
    "            w[1:] -= learning_rate * dw\n",
    "            # Mise à jour du biais\n",
    "            w[0] -= learning_rate * db\n",
    "\n",
    "            # Calcul et stockage du coût\n",
    "            cost = cost_function(X, y, w)\n",
    "            costs.append(cost)\n",
    "\n",
    "            total_iterations += 1  # Incrémenter le compteur d'itérations\n",
    "            if total_iterations == max_iterations:\n",
    "                return w, costs\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4d242500-18fc-48f2-bdf6-ac4d6140a986",
   "metadata": {},
   "source": [
    "# paramètres pour le test de notre fonction de recherche du batch-size \"optimal\" par exploration et heuristiques\n",
    "np.random.seed(1337)\n",
    "learning_rate = 0.01\n",
    "w_init= w.copy()\n",
    "max_iterations = 100\n",
    "acceptable_variance = 1e-2\n",
    "\n",
    "# Lançons notre fonction\n",
    "optimal_batch_size, batch_size_costs = find_optimal_batch_size(\n",
    "    X, y, w_init, learning_rate, acceptable_variance, max_iterations\n",
    ")\n",
    "\n",
    "print(f\"La taille de batch optimale est : {optimal_batch_size}\")\n",
    "print(\"Détails des coûts pour chaque taille de batch testée :\")\n",
    "for batch_size, info in batch_size_costs.items():\n",
    "    print(f\"Batch size: {batch_size}, Final cost: {info['final_cost']}, Cost variance: {info['cost_variance']}\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "772f5939-1f00-4e78-aa1d-37926a0db6d7",
   "metadata": {},
   "source": [
    "Notre fonction exécute bien la recherche, elle se fixe une intervalle de puissances de 2, entre 2 et la racine de la taille du dataset, sur lequel elle applique une descente de gradient limitée à 100 mises à jours. Elle vérifie le respect d'une contrainte de variance maximale acceptable chez les prétendants. Pour ensuite rendre un jugement, qui est ici en faveur d'un batch-size de taille 4. Ce résultat est cohérant avec nos résultats précédents. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6cccef-7da1-4dce-a999-172dc9f74adc",
   "metadata": {},
   "source": [
    "Nous pouvons également imaginer divers mécanismes adaptatifs ou le batch-size est ajusté au cours de la descente en fonction de critères de réponse à une anomalie. Par exemple, la fonction suivante implémente un mécanisme simple d'augmentation du batch-size en cas de stagnation de l'erreur pendant plusieurs itérations. La tolérance à l'ampleur de la stagnation et sa durée sont deux paramètres supplémentaires à définir en fonction des données. Le batch-size sera ainsi doublé à chaque anomalie de stagnation rencontrée et ce jusqu'à un seuil maximal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eb6fcb47-7182-4f57-a337-abba283e0d33",
   "metadata": {},
   "source": [
    "\n",
    "def stochastic_gradient_descent_batch_adaptive(X, y, w_random, learning_rate, epochs, initial_batch_size=1, max_batch_size=48, patience=1, tolerance=1e-3):\n",
    "    \"\"\"\n",
    "    Implémente l'algorithme de descente de gradient stochastique avec une adaptation dynamique de la taille du batch.\n",
    "    Le critère est la stagnation de la descente selon une tolérance à son seuil et aux nombres d'itérations stagnantes\n",
    "\n",
    "    Args:\n",
    "    X : matrice des caractéristiques (m échantillons x n caractéristiques)\n",
    "    y : vecteur des étiquettes (m échantillons)\n",
    "    w : vecteur initial des poids (n+1 dimensions, incluant le biais)\n",
    "    learning_rate : taux d'apprentissage pour la mise à jour des poids\n",
    "    epochs : nombre d'époques (passages complets sur les données)\n",
    "    initial_batch_size : taille de départ des mini-batchs (1 pour SGD pur)\n",
    "    max_batch_size : taille maximale du batch\n",
    "    patience : nombre d'époques à attendre avant d'augmenter la taille du batch si amélioration insuffisante\n",
    "    tolerance : seuil pour juger si l'amélioration du coût est négligeable\n",
    "\n",
    "    Returns:\n",
    "    w : vecteur final des poids optimisés\n",
    "    costs : liste des coûts à intervalles réguliers\n",
    "    \"\"\"\n",
    "    m = len(y)  # Nombre total d'échantillons\n",
    "    costs = []  # Liste pour stocker l'évolution du coût\n",
    "    w = w_random.copy() # pour ne pas altérer les poids d'entrée s'il faut les réutiliser\n",
    "    batch_size = initial_batch_size\n",
    "    stagnant_iters = 0  # Compteur pour suivre les époques où l'amélioration du coût est faible\n",
    "    iter_adaption = []\n",
    "    sizes = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Mélange aléatoire des indices des échantillons\n",
    "        indices = np.random.permutation(m)\n",
    "        X_shuffled = X[indices]\n",
    "        y_shuffled = y[indices]\n",
    "\n",
    "        # Parcours des mini-batchs\n",
    "        for i in range(0, m, batch_size):\n",
    "            # Sélection du mini-batch courant\n",
    "            X_batch = X_shuffled[i:i+batch_size]\n",
    "            y_batch = y_shuffled[i:i+batch_size]\n",
    "\n",
    "            # Calcul des prédictions pour le mini-batch\n",
    "            y_pred = predict(X_batch, w)\n",
    "\n",
    "            # Calcul du gradient pour les poids (sauf le biais) sur le mini-batch\n",
    "            dw = (1/batch_size) * np.dot(X_batch.T, (y_pred - y_batch))\n",
    "            # Calcul du gradient pour le biais sur le mini-batch\n",
    "            db = (1/batch_size) * np.sum(y_pred - y_batch)\n",
    "\n",
    "            # Mise à jour des poids (sauf le biais)\n",
    "            w[1:] -= learning_rate * dw\n",
    "            # Mise à jour du biais\n",
    "            w[0] -= learning_rate * db\n",
    "\n",
    "            # Calcul du coût après chaque itération\n",
    "            cost = cost_function(X, y, w)\n",
    "            costs.append(cost)\n",
    "\n",
    "        # Adaptation de la taille du batch si la réduction du coût est faible\n",
    "            if len(costs) > 1:\n",
    "                cost_diff = abs(costs[-2] - cost)\n",
    "                if cost_diff < tolerance:  # Si l'amélioration est inférieure au seuil de tolérance\n",
    "                    stagnant_iters += 1\n",
    "                else:\n",
    "                    stagnant_iters = 0  # Réinitialiser si une amélioration notable est détectée\n",
    "    \n",
    "                # Augmenter la taille du batch après un certain nombre d'itérations stagnantes\n",
    "                if stagnant_iters >= patience and batch_size < max_batch_size:\n",
    "                    batch_size = min(batch_size * 2, max_batch_size)\n",
    "                    sizes.append(batch_size)\n",
    "                    iter_adaption.append(len(costs))\n",
    "                    stagnant_iters = 0  # Réinitialiser le compteur\n",
    "                    print(f\"Itération {len(costs)}: Augmentation de la taille du batch à {batch_size}\")\n",
    "    \n",
    "                # Affichage périodique du coût\n",
    "                if len(costs) % 1000 == 0:\n",
    "                    print(f\"Itération {len(costs)}, Batch Size: {batch_size}, Coût: {cost:.4f}\")\n",
    "\n",
    "    return w, costs, iter_adaption, sizes"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ad221d10-dbeb-404e-b89a-4d690a8126ef",
   "metadata": {},
   "source": [
    "# Paramètres d'essai de la descente de gradient avec batch-size adaptatif\n",
    "np.random.seed(1337)\n",
    "w_init=w.copy()\n",
    "learning_rate=0.1 \n",
    "epochs=200\n",
    "initial_batch_size=2\n",
    "max_batch_size=256\n",
    "patience=3\n",
    "tolerance=1e-3\n",
    "\n",
    "# Appel de la fonction de gradient avec adaptation de la taille du batch                                                           \n",
    "w_adaptive_batch, costs_adaptive_batch, iters, sizes = stochastic_gradient_descent_batch_adaptive(X, y, w_init,\n",
    "                                                                                    learning_rate, \n",
    "                                                                                    epochs,\n",
    "                                                                                    initial_batch_size, \n",
    "                                                                                    max_batch_size, \n",
    "                                                                                    patience, \n",
    "                                                                                    tolerance)\n",
    "# Tracé des coûts\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Courbe de coût pour le SGD classique\n",
    "plt.plot(results[1][\"costs\"][:1000], label='SGD classique (n=1)', color='red')\n",
    "\n",
    "# Courbe de coût pour le SGD avec adaptation de la taille du batch\n",
    "plt.plot(costs_adaptive_batch[:1000], label='SGD batch adaptative', color='green')\n",
    "for i, iter_change in enumerate(iters):\n",
    "    plt.scatter(iter_change, costs_adaptive_batch[iter_change], color='blue', zorder=5)\n",
    "    plt.text(iter_change, costs_adaptive_batch[iter_change], f\" {sizes[i]}\", \n",
    "             fontsize=9, verticalalignment='bottom', horizontalalignment='left', color='blue')\n",
    "\n",
    "# Titre et légendes\n",
    "plt.title('Adaptation du batch-size par mécanisme de réponse à la stagnation')\n",
    "plt.xlabel('Itérations')\n",
    "plt.ylabel('Coût')\n",
    "plt.legend()\n",
    "\n",
    "# Affichage de la courbe\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "55c2578d-a676-494a-9ec3-163a07afe1f6",
   "metadata": {},
   "source": [
    "Comme le montre ce graphe, la descente de gradient adaptative, commence par entamer la descente avec un gradient bruité à cause du faible nombre d'échantillons pris en compte dans la mise à jour des poids. Lorsque les mises à jour deviennent trop érratiques et causent une stagnation, l'algorithme réagit en doublant la taille du batch, ce qui a pour effet d'affiner la justesse du gradient et de redynamiser la descente. Au fil des corrections, la stabilité de l'algorithme augmente de plus en plus. Au voisinage du minimum global, une grande taille de batch permet une meilleur approximation du minimum global de la perte empirique. Ici nous atteignons une valeur de 0.07 à la millième itération, avec un batch-size final de 256."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c968eb90-af90-455c-97e6-4b69c8bdad64",
   "metadata": {},
   "source": [
    "## **Conclusion du Bloc-1**\n",
    "\n",
    "\n",
    "Dans ce travail, nous avons implémenté et analysé diverses variantes de la descente de gradient appliquées à la régression logistique avec une fonction de perte convexe et lisse. L'étude s'est focalisée sur l'impact du learning-rate et du batch-size sur la convergence des algorithmes d'optimisation.\n",
    "\n",
    "Pour le learning Rate :\n",
    "\n",
    "- Un learning rate trop faible entraîne une convergence lente, augmentant le temps de calcul sans garantir l'atteinte rapide du minimum global.\n",
    "\n",
    "- Un learning rate trop élevé peut provoquer des oscillations ou une divergence de l'algorithme, rendant la convergence instable.\n",
    "\n",
    "- Des heuristiques empiriques et des bornes théoriques permettent d'approximer des plages de learning-rate acceptable sous certaines conditions.\n",
    "\n",
    "  \n",
    "Pour le batch Size :\n",
    "\n",
    "- Un batch size trop petit peut introduire une variance élevée dans la mise à jour des gradients, entraînant des oscillations et une convergence moins stable.\n",
    "  \n",
    "- Augmenter le batch size au-delà d'un certain seuil n'apporte pas d'amélioration significative en termes de vitesse de convergence, tout en augmentant le coût computationnel et les besoins en mémoire.\n",
    "\n",
    "  \n",
    "- Des méthodes adaptatives ajustant dynamiquement le batch size en fonction de critères tels que la stagnation de la perte peuvent optimiser la convergence.\n",
    "\n",
    "La maîtrise du learning rate et du batch size est essentielle pour optimiser l'apprentissage des modèles via la descente de gradient. Un équilibre judicieux entre ces hyperparamètres permet d'accélérer la convergence vers le minimum global de la fonction de perte tout en minimisant le coût computationnel. Les approches adaptatives et les considérations théoriques offrent des pistes prometteuses pour affiner ces paramètres.\n",
    "\n",
    "Dans la suite du travail en Bloc-2, les différentes descentes de gradient implémentées ci-dessus seront confrontées à un dataset du réel et mises en concurrence avec les implémentations officielles de la régression logistique. Il leur sera demandé de réaliser le même travail, qui sera évalué en fonction des métriques de performance en classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
